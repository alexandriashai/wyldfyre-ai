# Multi-Agent AI Infrastructure - Architecture Plan

## Overview

A self-hosted, installable AI infrastructure enabling multiple autonomous Claude agents to collaborate, learn, and manage server resources. Integrates Daniel Miessler's PAI (Personal AI Infrastructure) for self-improvement capabilities.

## Cost Constraints

| Category | Service | Cost |
|----------|---------|------|
| **Paid** | Claude API/Account | Per-usage |
| **Paid** | OpenAI API (Embeddings, Whisper STT, TTS) | Per-usage |
| **Paid** | AWS Secrets Manager | Per-usage (minimal) |
| **Paid** | Cloudflare API (Pro/Business) | Account subscription |
| **Free** | GitHub (with PAT) | Free |
| **Free** | Everything else | $0 |

### External Service Integrations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      EXTERNAL SERVICE INTEGRATIONS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS SECRETS MGR   â”‚  â”‚    CLOUDFLARE API   â”‚  â”‚      GITHUB         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                     â”‚  â”‚                     â”‚  â”‚                     â”‚
â”‚ â€¢ API keys storage  â”‚  â”‚ â€¢ DNS management    â”‚  â”‚ â€¢ Code backup       â”‚
â”‚ â€¢ DB credentials    â”‚  â”‚ â€¢ CDN caching       â”‚  â”‚ â€¢ Version control   â”‚
â”‚ â€¢ JWT secrets       â”‚  â”‚ â€¢ DDoS protection   â”‚  â”‚ â€¢ Config sync       â”‚
â”‚ â€¢ Rotation support  â”‚  â”‚ â€¢ SSL certificates  â”‚  â”‚ â€¢ Memory archival   â”‚
â”‚ â€¢ IAM integration   â”‚  â”‚ â€¢ Firewall rules    â”‚  â”‚ â€¢ Agent prompts     â”‚
â”‚                     â”‚  â”‚ â€¢ Analytics         â”‚  â”‚ â€¢ Collaboration     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   AI INFRASTRUCTURE       â”‚
                    â”‚   (Your Server)           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MULTI-AGENT AI INFRASTRUCTURE                            â”‚
â”‚                         with PAI Integration                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                 INTERNET
                                     â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     NGINX (TLS + Reverse      â”‚
                     â”‚        Proxy + Domains)       â”‚
                     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
                     â”‚   â”‚ domain1.com â†’ /www1 â”‚     â”‚
                     â”‚   â”‚ domain2.com â†’ /www2 â”‚     â”‚
                     â”‚   â”‚ portal.ai   â†’ :3000 â”‚     â”‚
                     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚                           â”‚
         â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WEB PORTAL    â”‚      â”‚    API GATEWAY      â”‚      â”‚  VOICE SERVICE  â”‚
â”‚   (Next.js)     â”‚      â”‚    (FastAPI)        â”‚      â”‚  (Whisper+TTS)  â”‚
â”‚   Port: 3000    â”‚      â”‚    Port: 8000       â”‚      â”‚  Port: 8001     â”‚
â”‚   [MIT]         â”‚      â”‚    [MIT]            â”‚      â”‚  [OpenAI API]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      REDIS MESSAGE BUS    â”‚
                     â”‚   Pub/Sub + Streams       â”‚
                     â”‚   Port: 6379 [BSD]        â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TMUX SESSION: ai-infrastructure                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚  â”‚  â”‚ SUPERVISOR  â”‚ â”‚ CODE AGENT  â”‚ â”‚ DATA AGENT  â”‚             â”‚  â”‚
â”‚  â”‚  â”‚   Window 0  â”‚ â”‚  Window 1   â”‚ â”‚  Window 2   â”‚             â”‚  â”‚
â”‚  â”‚  â”‚  (Claude)   â”‚ â”‚  (Claude)   â”‚ â”‚  (Claude)   â”‚  ...        â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚  â”‚         â”‚               â”‚               â”‚                     â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â”‚                         â”‚                                     â”‚  â”‚
â”‚  â”‚              PAI INTEGRATION LAYER                            â”‚  â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚  â”‚
â”‚  â”‚         â”‚   THE ALGORITHM (7-Phase)     â”‚                     â”‚  â”‚
â”‚  â”‚         â”‚ OBSERVEâ†’THINKâ†’PLANâ†’BUILDâ†’     â”‚                     â”‚  â”‚
â”‚  â”‚         â”‚ EXECUTEâ†’VERIFYâ†’LEARN          â”‚                     â”‚  â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  SSH ACCESS: ssh root@server â†’ tmux attach -t ai-infrastructure     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                         â”‚                             â”‚
         â–¼                         â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     QDRANT      â”‚    â”‚    POSTGRESQL       â”‚    â”‚    PAI MEMORY       â”‚
â”‚  Vector Store   â”‚    â”‚   Conversations     â”‚    â”‚   (File-based)      â”‚
â”‚  Port: 6333     â”‚    â”‚   Users, Tasks      â”‚    â”‚                     â”‚
â”‚  [Apache 2.0]   â”‚    â”‚   Port: 5432 [BSD]  â”‚    â”‚   MEMORY/           â”‚
â”‚                 â”‚    â”‚                     â”‚    â”‚   â”œâ”€â”€ Learning/     â”‚
â”‚  - Embeddings   â”‚    â”‚                     â”‚    â”‚   â”œâ”€â”€ Signals/      â”‚
â”‚  - RAG Memory   â”‚    â”‚                     â”‚    â”‚   â””â”€â”€ Work/         â”‚
â”‚  - Knowledge    â”‚    â”‚                     â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SERVER MANAGEMENT LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  DOMAIN MANAGEMENT          WEB ROOTS              SERVICES                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ /etc/nginx/    â”‚        â”‚ /var/www/      â”‚     â”‚ systemd units  â”‚           â”‚
â”‚  â”‚   sites-avail/ â”‚        â”‚   domain1/     â”‚     â”‚ docker         â”‚           â”‚
â”‚  â”‚   sites-enable/â”‚        â”‚   domain2/     â”‚     â”‚ certbot        â”‚           â”‚
â”‚  â”‚   ssl/         â”‚        â”‚   portal/      â”‚     â”‚ fail2ban       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              EXTERNAL APIs (Paid)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚    ANTHROPIC        â”‚              â”‚      OPENAI         â”‚                   â”‚
â”‚  â”‚    Claude API       â”‚              â”‚  - Embeddings       â”‚                   â”‚
â”‚  â”‚    (All Agents)     â”‚              â”‚  - Whisper (STT)    â”‚                   â”‚
â”‚  â”‚                     â”‚              â”‚  - TTS              â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Technology Stack (All Free/Open Source except APIs)

### Core Infrastructure

| Component | Technology | License | Purpose |
|-----------|------------|---------|---------|
| Message Bus | Redis | BSD-3 | Pub/Sub, Streams, Caching |
| Vector DB | Qdrant | Apache 2.0 | Embeddings, RAG, Knowledge |
| Relational DB | PostgreSQL | PostgreSQL License | Users, Tasks, Conversations |
| Reverse Proxy | Nginx | BSD-2 | TLS, Domains, Load Balancing |
| SSL Certs | Let's Encrypt + Certbot | Free | TLS Certificates |
| Containers | Docker + Compose | Apache 2.0 | Isolation, Deployment |

### Application Layer

| Component | Technology | License | Purpose |
|-----------|------------|---------|---------|
| API Server | FastAPI | MIT | REST + WebSocket API |
| Frontend | Next.js 14 | MIT | Web Portal |
| UI Components | shadcn/ui + Tailwind | MIT | Component Library |
| Tmux Control | libtmux | MIT | Agent Process Management |
| Session Manager | tmuxp | MIT | Tmux Configuration |

### AI Services (Paid)

| Service | Provider | Purpose |
|---------|----------|---------|
| Agent LLM | Claude API | All agent intelligence |
| Embeddings | OpenAI text-embedding-3-small | Vector embeddings |
| Speech-to-Text | OpenAI Whisper | Voice transcription |
| Text-to-Speech | OpenAI TTS | Voice synthesis |

### PAI Integration

| Component | Source | Purpose |
|-----------|--------|---------|
| The Algorithm | PAI | 7-phase improvement cycle |
| Memory System | PAI | Hot/Warm/Cold learning |
| Hook System | PAI | Event-driven automation |
| TELOS Config | PAI | Goal/value alignment |

---

## Agent Architecture

### Agent Types & Responsibilities

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           AGENT HIERARCHY                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   SUPERVISOR AGENT  â”‚
                        â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
                        â”‚   â€¢ Task routing    â”‚
                        â”‚   â€¢ Orchestration   â”‚
                        â”‚   â€¢ User interface  â”‚
                        â”‚   â€¢ Conflict res.   â”‚
                        â”‚   â€¢ PAI Algorithm   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚           â”‚           â”‚              â”‚
        â–¼              â–¼           â–¼           â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODE AGENT  â”‚ â”‚  DATA AGENT  â”‚ â”‚ INFRA AGENT  â”‚ â”‚RESEARCH AGENTâ”‚ â”‚   QA AGENT   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ â€¢ Git ops    â”‚ â”‚ â€¢ SQL/DB     â”‚ â”‚ â€¢ Docker     â”‚ â”‚ â€¢ Web search â”‚ â”‚ â€¢ Testing    â”‚
â”‚ â€¢ Coding     â”‚ â”‚ â€¢ Analysis   â”‚ â”‚ â€¢ Nginx      â”‚ â”‚ â€¢ Docs       â”‚ â”‚ â€¢ Review     â”‚
â”‚ â€¢ Refactor   â”‚ â”‚ â€¢ ETL        â”‚ â”‚ â€¢ Domains    â”‚ â”‚ â€¢ Synthesis  â”‚ â”‚ â€¢ Security   â”‚
â”‚ â€¢ Debug      â”‚ â”‚ â€¢ Backups    â”‚ â”‚ â€¢ SSL/TLS    â”‚ â”‚ â€¢ Learning   â”‚ â”‚ â€¢ Validation â”‚
â”‚              â”‚ â”‚              â”‚ â”‚ â€¢ Monitoring â”‚ â”‚              â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Communication Protocol

```python
# Message Schema
{
    "id": "uuid",
    "timestamp": "ISO-8601",
    "source": "supervisor",
    "target": "code_agent",  # or "*" for broadcast
    "type": "task|result|handoff|query|heartbeat|learn",
    "priority": 1-10,
    "payload": {
        "task_id": "uuid",
        "action": "implement_feature",
        "context": {...},
        "memory_refs": ["qdrant_id_1", "qdrant_id_2"]
    },
    "pai": {
        "algorithm_phase": "EXECUTE",
        "verification_criteria": [...],
        "learning_signals": []
    }
}
```

### Inter-Agent Patterns

```
SEQUENTIAL:     Supervisor â†’ Agent A â†’ Agent B â†’ Supervisor
PARALLEL:       Supervisor â†’ [Agent A, Agent B, Agent C] â†’ Supervisor
PEER CONSULT:   Agent A â†â†’ Agent B (direct query/response)
BROADCAST:      Agent A â†’ Redis Pub/Sub â†’ All Agents (knowledge share)
HANDOFF:        Agent A â†’ Agent B (transfer ownership)
```

---

## PAI Integration

### The Algorithm (7-Phase Improvement Cycle)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         THE ALGORITHM                                       â”‚
â”‚                   (Continuous Improvement Engine)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ OBSERVE  â”‚â”€â”€â”€â”€â–¶â”‚  THINK   â”‚â”€â”€â”€â”€â–¶â”‚   PLAN   â”‚â”€â”€â”€â”€â–¶â”‚  BUILD   â”‚
    â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚
    â”‚ Gather   â”‚     â”‚ Generate â”‚     â”‚ Select   â”‚     â”‚ Define   â”‚
    â”‚ context  â”‚     â”‚ options  â”‚     â”‚ approach â”‚     â”‚ criteria â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                                            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ EXECUTE  â”‚â”€â”€â”€â”€â–¶â”‚  VERIFY  â”‚â”€â”€â”€â”€â–¶â”‚  LEARN   â”‚
    â”‚          â”‚     â”‚          â”‚     â”‚          â”‚
    â”‚ Perform  â”‚     â”‚ Test vs  â”‚     â”‚ Extract  â”‚â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ work     â”‚     â”‚ criteria â”‚     â”‚ insights â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                           â”‚                              â”‚
                           â”‚ FAIL                         â”‚
                           â–¼                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
                    â”‚ Trace back   â”‚                     â”‚
                    â”‚ to failing   â”‚                     â”‚
                    â”‚ phase        â”‚                     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
                                                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      MEMORY SYSTEM                                      â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚  â”‚    HOT      â”‚  â”‚      WARM       â”‚  â”‚        COLD          â”‚        â”‚
    â”‚  â”‚  (CAPTURE)  â”‚  â”‚   (SYNTHESIS)   â”‚  â”‚   (APPLICATION)      â”‚        â”‚
    â”‚  â”‚             â”‚  â”‚                 â”‚  â”‚                      â”‚        â”‚
    â”‚  â”‚ Real-time   â”‚  â”‚ Learnings by    â”‚  â”‚ Immutable archive    â”‚        â”‚
    â”‚  â”‚ task traces â”‚  â”‚ algorithm phase â”‚  â”‚ Historical reference â”‚        â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PAI Memory Structure

```
MEMORY/
â”œâ”€â”€ Learning/
â”‚   â”œâ”€â”€ OBSERVE/           # Context gathering improvements
â”‚   â”œâ”€â”€ THINK/             # Solution generation patterns
â”‚   â”œâ”€â”€ PLAN/              # Planning improvements
â”‚   â”œâ”€â”€ BUILD/             # Criteria definition learnings
â”‚   â”œâ”€â”€ EXECUTE/           # Execution optimizations
â”‚   â”œâ”€â”€ VERIFY/            # Verification improvements
â”‚   â”œâ”€â”€ LEARN/             # Meta-learnings
â”‚   â””â”€â”€ ALGORITHM/         # Algorithm self-improvements
â”‚
â”œâ”€â”€ Signals/
â”‚   â”œâ”€â”€ ratings/           # Explicit user ratings
â”‚   â”œâ”€â”€ sentiment/         # Implicit tone analysis
â”‚   â”œâ”€â”€ behavioral/        # Loopbacks, retries, abandons
â”‚   â””â”€â”€ verification/      # Objective pass/fail
â”‚
â””â”€â”€ Work/
    â”œâ”€â”€ active/            # Current task contexts
    â””â”€â”€ archive/           # Completed task records
```

### Hook System Events

```python
HOOKS = {
    "SessionStart":     "Initialize agent, load context",
    "SessionEnd":       "Persist state, cleanup",
    "UserPromptSubmit": "Capture input, route to supervisor",
    "Stop":             "Task completion, trigger VERIFY",
    "SubagentStop":     "Child agent completed, aggregate",
    "PreToolUse":       "Validate tool call, log intent",
    "PostToolUse":      "Capture result, update memory",
    "PreCompact":       "Context optimization checkpoint"
}
```

---

## SSH & Tmux Access

### Remote Access Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SSH ACCESS ARCHITECTURE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Admin Workstation
          â”‚
          â”‚ SSH (Port 22, Key Auth)
          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         SERVER                                          â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚                    TMUX SESSION: ai-infrastructure                â”‚  â”‚
    â”‚  â”‚                                                                   â”‚  â”‚
    â”‚  â”‚  Window 0: supervisor    â”‚ Window 1: code     â”‚ Window 2: data   â”‚  â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚
    â”‚  â”‚  â”‚ $ claude            â”‚ â”‚ â”‚ $ claude        â”‚â”‚ â”‚ $ claude      â”‚â”‚  â”‚
    â”‚  â”‚  â”‚ [Supervisor Agent]  â”‚ â”‚ â”‚ [Code Agent]    â”‚â”‚ â”‚ [Data Agent]  â”‚â”‚  â”‚
    â”‚  â”‚  â”‚                     â”‚ â”‚ â”‚                 â”‚â”‚ â”‚               â”‚â”‚  â”‚
    â”‚  â”‚  â”‚ Listening on Redis  â”‚ â”‚ â”‚ Listening...    â”‚â”‚ â”‚ Listening...  â”‚â”‚  â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚
    â”‚  â”‚                          â”‚                    â”‚                   â”‚  â”‚
    â”‚  â”‚  Window 3: infra         â”‚ Window 4: research â”‚ Window 5: qa     â”‚  â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚
    â”‚  â”‚  â”‚ $ claude            â”‚ â”‚ â”‚ $ claude        â”‚â”‚ â”‚ $ claude      â”‚â”‚  â”‚
    â”‚  â”‚  â”‚ [Infra Agent]       â”‚ â”‚ â”‚ [Research Agent]â”‚â”‚ â”‚ [QA Agent]    â”‚â”‚  â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚
    â”‚  â”‚                                                                   â”‚  â”‚
    â”‚  â”‚  Window 6: monitor       â”‚ Window 7: logs                        â”‚  â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚
    â”‚  â”‚  â”‚ $ htop / btop       â”‚ â”‚ â”‚ $ tail -f /var/log/ai-infra/*.log  â”‚â”‚  â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    COMMANDS:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ssh root@server                           # Connect to server
    tmux attach -t ai-infrastructure          # Attach to agent session
    tmux select-window -t ai-infrastructure:0 # Switch to supervisor
    tmux select-window -t ai-infrastructure:1 # Switch to code agent
    Ctrl+b d                                  # Detach from session
    Ctrl+b n                                  # Next window
    Ctrl+b p                                  # Previous window
```

### SSH Security Configuration

```bash
# /etc/ssh/sshd_config additions
PermitRootLogin prohibit-password    # Key-only root access
PasswordAuthentication no            # No password auth
PubkeyAuthentication yes             # Key auth enabled
AllowUsers root admin                # Whitelist users
MaxAuthTries 3                       # Limit attempts
ClientAliveInterval 300              # Keep-alive
ClientAliveCountMax 2                # Disconnect on timeout
```

---

## Multi-Domain Management

### Domain Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MULTI-DOMAIN ARCHITECTURE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              INTERNET
                                  â”‚
                                  â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              NGINX                    â”‚
              â”‚         (Reverse Proxy)               â”‚
              â”‚                                       â”‚
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
              â”‚  â”‚     TLS TERMINATION             â”‚  â”‚
              â”‚  â”‚  - Let's Encrypt Certificates   â”‚  â”‚
              â”‚  â”‚  - Auto-renewal via Certbot     â”‚  â”‚
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
              â”‚                                       â”‚
              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
              â”‚  â”‚     VIRTUAL HOSTS               â”‚  â”‚
              â”‚  â”‚                                 â”‚  â”‚
              â”‚  â”‚  api.example.com    â†’ :8000     â”‚  â”‚
              â”‚  â”‚  portal.example.com â†’ :3000     â”‚  â”‚
              â”‚  â”‚  app1.example.com   â†’ /var/www/app1  â”‚
              â”‚  â”‚  app2.example.com   â†’ /var/www/app2  â”‚
              â”‚  â”‚  blog.example.com   â†’ /var/www/blog  â”‚
              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚         â”‚         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /var/www/app1  â”‚  â”‚  /var/www/app2  â”‚  â”‚  /var/www/blog  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  index.html     â”‚  â”‚  index.html     â”‚  â”‚  index.html     â”‚
â”‚  assets/        â”‚  â”‚  assets/        â”‚  â”‚  posts/         â”‚
â”‚  .htaccess      â”‚  â”‚  api/           â”‚  â”‚  themes/        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nginx Configuration Structure

```
/etc/nginx/
â”œâ”€â”€ nginx.conf                 # Main config
â”œâ”€â”€ sites-available/
â”‚   â”œâ”€â”€ default
â”‚   â”œâ”€â”€ api.example.com       # API server
â”‚   â”œâ”€â”€ portal.example.com    # Web portal
â”‚   â”œâ”€â”€ app1.example.com      # Static site 1
â”‚   â”œâ”€â”€ app2.example.com      # Static site 2
â”‚   â””â”€â”€ template.conf         # Template for new domains
â”œâ”€â”€ sites-enabled/            # Symlinks to active sites
â”œâ”€â”€ ssl/
â”‚   â””â”€â”€ dhparam.pem          # DH parameters
â”œâ”€â”€ snippets/
â”‚   â”œâ”€â”€ ssl-params.conf      # SSL settings
â”‚   â”œâ”€â”€ security-headers.conf # Security headers
â”‚   â””â”€â”€ proxy-params.conf    # Proxy settings
â””â”€â”€ conf.d/
    â”œâ”€â”€ rate-limiting.conf   # Rate limiting rules
    â””â”€â”€ gzip.conf            # Compression settings
```

### Infrastructure Agent Domain Commands

```python
# Commands the Infrastructure Agent can execute
DOMAIN_COMMANDS = {
    "add_domain": {
        "steps": [
            "Create /var/www/{domain}",
            "Create nginx config from template",
            "Enable site (symlink)",
            "Request SSL cert via certbot",
            "Reload nginx",
            "Verify domain accessible"
        ]
    },
    "remove_domain": {
        "steps": [
            "Disable site (remove symlink)",
            "Archive web root",
            "Remove nginx config",
            "Revoke SSL cert (optional)",
            "Reload nginx"
        ]
    },
    "update_ssl": {
        "steps": [
            "Run certbot renew",
            "Verify cert validity",
            "Reload nginx if renewed"
        ]
    },
    "deploy_site": {
        "steps": [
            "Pull/copy new files to web root",
            "Set permissions",
            "Clear cache if applicable",
            "Verify deployment"
        ]
    }
}
```

---

## Directory Structure

```
/home/user/AI-Infrastructure/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE (MIT)
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.prod.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ install.sh                    # One-line installer
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ deployment.md
â”‚   â”œâ”€â”€ agents.md
â”‚   â”œâ”€â”€ api.md
â”‚   â””â”€â”€ security.md
â”‚
â”œâ”€â”€ pai/                          # PAI Integration
â”‚   â”œâ”€â”€ .claude/                  # Claude configurations
â”‚   â”‚   â”œâ”€â”€ settings.json
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”œâ”€â”€ MEMORY/                   # PAI Memory System
â”‚   â”‚   â”œâ”€â”€ Learning/
â”‚   â”‚   â”‚   â”œâ”€â”€ OBSERVE/
â”‚   â”‚   â”‚   â”œâ”€â”€ THINK/
â”‚   â”‚   â”‚   â”œâ”€â”€ PLAN/
â”‚   â”‚   â”‚   â”œâ”€â”€ BUILD/
â”‚   â”‚   â”‚   â”œâ”€â”€ EXECUTE/
â”‚   â”‚   â”‚   â”œâ”€â”€ VERIFY/
â”‚   â”‚   â”‚   â”œâ”€â”€ LEARN/
â”‚   â”‚   â”‚   â””â”€â”€ ALGORITHM/
â”‚   â”‚   â”œâ”€â”€ Signals/
â”‚   â”‚   â”‚   â”œâ”€â”€ ratings/
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment/
â”‚   â”‚   â”‚   â”œâ”€â”€ behavioral/
â”‚   â”‚   â”‚   â””â”€â”€ verification/
â”‚   â”‚   â””â”€â”€ Work/
â”‚   â”‚       â”œâ”€â”€ active/
â”‚   â”‚       â””â”€â”€ archive/
â”‚   â”œâ”€â”€ TELOS/                    # Goal Configuration
â”‚   â”‚   â”œâ”€â”€ mission.md
â”‚   â”‚   â”œâ”€â”€ vision.md
â”‚   â”‚   â”œâ”€â”€ values.md
â”‚   â”‚   â”œâ”€â”€ priorities.md
â”‚   â”‚   â””â”€â”€ success.md
â”‚   â””â”€â”€ hooks/                    # Event Hooks
â”‚       â”œâ”€â”€ session_start.py
â”‚       â”œâ”€â”€ session_end.py
â”‚       â”œâ”€â”€ user_prompt.py
â”‚       â”œâ”€â”€ task_complete.py
â”‚       â””â”€â”€ tool_use.py
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                     # Shared utilities
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ src/ai_core/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ logging.py
â”‚   â”‚       â””â”€â”€ exceptions.py
â”‚   â”‚
â”‚   â”œâ”€â”€ messaging/                # Redis messaging
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ src/ai_messaging/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ bus.py
â”‚   â”‚       â”œâ”€â”€ publisher.py
â”‚   â”‚       â”œâ”€â”€ subscriber.py
â”‚   â”‚       â”œâ”€â”€ streams.py
â”‚   â”‚       â””â”€â”€ protocols.py
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                   # Vector DB + PAI memory
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ src/ai_memory/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ embeddings.py     # OpenAI embeddings
â”‚   â”‚       â”œâ”€â”€ qdrant_store.py
â”‚   â”‚       â”œâ”€â”€ retriever.py
â”‚   â”‚       â”œâ”€â”€ pai_memory.py     # PAI integration
â”‚   â”‚       â””â”€â”€ schemas.py
â”‚   â”‚
â”‚   â””â”€â”€ tmux_manager/             # Tmux orchestration
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ src/ai_tmux/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ session.py
â”‚           â”œâ”€â”€ agent_runner.py
â”‚           â”œâ”€â”€ monitor.py
â”‚           â””â”€â”€ config.py
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/                      # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ src/api/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚       â”œâ”€â”€ config.py
â”‚   â”‚       â”œâ”€â”€ dependencies.py
â”‚   â”‚       â”œâ”€â”€ middleware/
â”‚   â”‚       â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚       â”‚   â”œâ”€â”€ rate_limit.py
â”‚   â”‚       â”‚   â””â”€â”€ logging.py
â”‚   â”‚       â”œâ”€â”€ routes/
â”‚   â”‚       â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚       â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚       â”‚   â”œâ”€â”€ agents.py
â”‚   â”‚       â”‚   â”œâ”€â”€ tasks.py
â”‚   â”‚       â”‚   â”œâ”€â”€ memory.py
â”‚   â”‚       â”‚   â”œâ”€â”€ domains.py    # Domain management
â”‚   â”‚       â”‚   â””â”€â”€ voice.py
â”‚   â”‚       â”œâ”€â”€ websocket/
â”‚   â”‚       â”‚   â”œâ”€â”€ manager.py
â”‚   â”‚       â”‚   â””â”€â”€ handlers.py
â”‚   â”‚       â””â”€â”€ services/
â”‚   â”‚           â”œâ”€â”€ auth_service.py
â”‚   â”‚           â”œâ”€â”€ chat_service.py
â”‚   â”‚           â”œâ”€â”€ agent_service.py
â”‚   â”‚           â””â”€â”€ domain_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ supervisor/               # Supervisor agent
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”œâ”€â”€ AGENT.md              # System prompt
â”‚   â”‚   â””â”€â”€ src/supervisor/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚       â”œâ”€â”€ orchestrator.py
â”‚   â”‚       â”œâ”€â”€ router.py
â”‚   â”‚       â”œâ”€â”€ aggregator.py
â”‚   â”‚       â”œâ”€â”€ algorithm.py      # PAI Algorithm
â”‚   â”‚       â””â”€â”€ prompts/
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base/                 # Base agent class
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â””â”€â”€ src/agent_base/
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚       â”œâ”€â”€ agent.py
â”‚   â”‚   â”‚       â”œâ”€â”€ tools.py
â”‚   â”‚   â”‚       â”œâ”€â”€ memory.py
â”‚   â”‚   â”‚       â””â”€â”€ communication.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ code_agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ AGENT.md
â”‚   â”‚   â”‚   â””â”€â”€ src/code_agent/
â”‚   â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data_agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ AGENT.md
â”‚   â”‚   â”‚   â””â”€â”€ src/data_agent/
â”‚   â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ infra_agent/          # Server/domain management
â”‚   â”‚   â”‚   â”œâ”€â”€ AGENT.md
â”‚   â”‚   â”‚   â””â”€â”€ src/infra_agent/
â”‚   â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚           â”œâ”€â”€ nginx.py
â”‚   â”‚   â”‚           â”œâ”€â”€ certbot.py
â”‚   â”‚   â”‚           â”œâ”€â”€ docker.py
â”‚   â”‚   â”‚           â”œâ”€â”€ systemd.py
â”‚   â”‚   â”‚           â””â”€â”€ domains.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ research_agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ AGENT.md
â”‚   â”‚   â”‚   â””â”€â”€ src/research_agent/
â”‚   â”‚   â”‚       â”œâ”€â”€ main.py
â”‚   â”‚   â”‚       â””â”€â”€ tools/
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ qa_agent/
â”‚   â”‚       â”œâ”€â”€ AGENT.md
â”‚   â”‚       â””â”€â”€ src/qa_agent/
â”‚   â”‚           â”œâ”€â”€ main.py
â”‚   â”‚           â””â”€â”€ tools/
â”‚   â”‚
â”‚   â””â”€â”€ voice/                    # Voice processing
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ src/voice_service/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ main.py
â”‚           â”œâ”€â”€ transcription.py  # OpenAI Whisper
â”‚           â”œâ”€â”€ synthesis.py      # OpenAI TTS
â”‚           â””â”€â”€ streaming.py
â”‚
â”œâ”€â”€ web/                          # Next.js frontend
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ layout.tsx
â”‚       â”‚   â”œâ”€â”€ page.tsx
â”‚       â”‚   â”œâ”€â”€ (auth)/
â”‚       â”‚   â”‚   â”œâ”€â”€ login/
â”‚       â”‚   â”‚   â””â”€â”€ register/
â”‚       â”‚   â””â”€â”€ (dashboard)/
â”‚       â”‚       â”œâ”€â”€ chat/
â”‚       â”‚       â”œâ”€â”€ agents/
â”‚       â”‚       â”œâ”€â”€ domains/      # Domain management UI
â”‚       â”‚       â”œâ”€â”€ memory/
â”‚       â”‚       â””â”€â”€ settings/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ui/               # shadcn/ui
â”‚       â”‚   â”œâ”€â”€ chat/
â”‚       â”‚   â”œâ”€â”€ agents/
â”‚       â”‚   â”œâ”€â”€ domains/
â”‚       â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ hooks/
â”‚       â”œâ”€â”€ lib/
â”‚       â””â”€â”€ stores/
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ seeds/
â”‚   â””â”€â”€ models/
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”‚   â”œâ”€â”€ Dockerfile.agent
â”‚   â”‚   â”œâ”€â”€ Dockerfile.web
â”‚   â”‚   â””â”€â”€ Dockerfile.voice
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”‚   â”œâ”€â”€ sites-available/
â”‚   â”‚   â”‚   â””â”€â”€ template.conf
â”‚   â”‚   â””â”€â”€ snippets/
â”‚   â”œâ”€â”€ systemd/
â”‚   â”‚   â”œâ”€â”€ ai-infrastructure.service
â”‚   â”‚   â”œâ”€â”€ ai-api.service
â”‚   â”‚   â””â”€â”€ ai-agents.service
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ setup.sh
â”‚       â”œâ”€â”€ start-agents.sh
â”‚       â”œâ”€â”€ add-domain.sh
â”‚       â””â”€â”€ backup.sh
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml               # Agent definitions
â”‚   â”œâ”€â”€ domains.yaml              # Domain configurations
â”‚   â”œâ”€â”€ tmux/
â”‚   â”‚   â””â”€â”€ session.yaml          # tmuxp config
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ supervisor.md
â”‚       â”œâ”€â”€ code_agent.md
â”‚       â”œâ”€â”€ data_agent.md
â”‚       â”œâ”€â”€ infra_agent.md
â”‚       â”œâ”€â”€ research_agent.md
â”‚       â””â”€â”€ qa_agent.md
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## User Interface

### Web Portal Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           WEB PORTAL LAYOUT                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”  AI Infrastructure                    [User] â–¼  [Settings]  [Logout]â”‚
â”‚  â”‚ â—‰â—‰â—‰ â”‚                                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜                                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             â”‚                                                               â”‚
â”‚   SIDEBAR   â”‚                    MAIN CONTENT                               â”‚
â”‚             â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ğŸ’¬ Chat â”‚ â”‚  â”‚                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚ [Supervisor] Today at 2:30 PM                   â”‚   â”‚ â”‚
â”‚  â”‚ğŸ¤– Agentsâ”‚ â”‚  â”‚  â”‚ I've analyzed your request. Here's my plan:    â”‚   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚ 1. Code Agent will implement the API            â”‚   â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚ 2. Data Agent will set up the database         â”‚   â”‚ â”‚
â”‚  â”‚ğŸŒ Domainâ”‚ â”‚  â”‚  â”‚ 3. QA Agent will write tests                   â”‚   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚ğŸ§  Memoryâ”‚ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚ [Code Agent] Working...                         â”‚   â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 60%                        â”‚   â”‚ â”‚
â”‚  â”‚âš™ï¸ Settingsâ”‚ â”‚  â”‚  â”‚ Currently implementing user authentication...   â”‚   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚             â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                                                               â”‚
â”‚  AGENTS     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚â—‰ Super â”‚ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”â”‚ â”‚
â”‚  â”‚â—‰ Code  â”‚ â”‚  â”‚  â”‚ Type your message...                     â”‚ â”‚ğŸ“â”‚ â”‚ğŸ¤â”‚â”‚ â”‚
â”‚  â”‚â—‰ Data  â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”˜ â””â”€â”€â”˜â”‚ â”‚
â”‚  â”‚â—‰ Infra â”‚ â”‚  â”‚        [Attach Files]        [Voice Input]    [Send â¤] â”‚ â”‚
â”‚  â”‚â—‰ Researchâ”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚â—‰ QA    â”‚ â”‚                                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                                                               â”‚
â”‚             â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PAGES:
â”€â”€â”€â”€â”€
/chat        - Main chat interface with supervisor
/agents      - Agent status, logs, controls
/domains     - Domain management (add/remove/deploy)
/memory      - Browse vector DB, view learnings
/settings    - API keys, preferences, TELOS config
```

### Chat Features

- **Text Input**: Markdown support, code blocks
- **File Upload**: Images, documents, code files
- **Voice Input**: Push-to-talk, continuous listening
- **Voice Output**: TTS for agent responses
- **Streaming**: Real-time response streaming
- **Agent Status**: Live indicator of which agents are working

---

## Security Architecture

### Permission Model

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PERMISSION LEVELS                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LEVEL 0: RESTRICTED (Default)
â”œâ”€â”€ Read: /workspace only
â”œâ”€â”€ Write: None
â”œâ”€â”€ Network: None
â””â”€â”€ Execute: None

LEVEL 1: STANDARD (Code/Data/Research/QA Agents)
â”œâ”€â”€ Read: /workspace, /var/www (read-only)
â”œâ”€â”€ Write: /workspace
â”œâ”€â”€ Network: HTTPS to allowlist (github.com, pypi.org, npm.js)
â””â”€â”€ Execute: git, npm, pip, pytest, approved tools

LEVEL 2: ELEVATED (Infrastructure Agent)
â”œâ”€â”€ Read: /workspace, /var/www, /etc/nginx, system logs
â”œâ”€â”€ Write: /workspace, /var/www, /etc/nginx/sites-available
â”œâ”€â”€ Network: Full outbound HTTPS
â””â”€â”€ Execute: docker, nginx, certbot, systemctl (limited)

LEVEL 3: PRIVILEGED (Supervisor + Human Approval)
â”œâ”€â”€ Read: Full system
â”œâ”€â”€ Write: Full system (with audit)
â”œâ”€â”€ Network: Full
â””â”€â”€ Execute: All (with confirmation for destructive ops)

ESCALATION:
Agent requests elevated permission â†’ Supervisor evaluates â†’
Auto-approve (within policy) OR Human approval required
All actions logged to audit trail
```

### Authentication Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User    â”‚â”€â”€â”€â”€â–¶â”‚  Portal  â”‚â”€â”€â”€â”€â–¶â”‚   API    â”‚â”€â”€â”€â”€â–¶â”‚  Redis   â”‚
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚
â”‚ 1. Login â”‚     â”‚ 2. OAuth/â”‚     â”‚ 3. Issue â”‚     â”‚ 4. Store â”‚
â”‚    form  â”‚     â”‚    Creds â”‚     â”‚    JWT   â”‚     â”‚  session â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚ WebSocketâ”‚
                                  â”‚ Connect  â”‚
                                  â”‚ w/ JWT   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## External Service Integrations

### AWS Secrets Manager

All sensitive credentials are stored in AWS Secrets Manager for secure, centralized management.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS SECRETS MANAGER INTEGRATION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    AWS Secrets Manager                         AI Infrastructure
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    ai-infrastructure/                         Application Startup
    â”œâ”€â”€ anthropic-api-key      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚
    â”œâ”€â”€ openai-api-key         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚ Secrets loaded
    â”œâ”€â”€ postgres-credentials   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚ into memory
    â”œâ”€â”€ redis-password         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚ (not env files)
    â”œâ”€â”€ qdrant-api-key         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚
    â”œâ”€â”€ jwt-secret             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚
    â”œâ”€â”€ cloudflare-token       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚
    â””â”€â”€ github-pat             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â–¼

    FEATURES:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ Automatic rotation support
    â€¢ IAM-based access control
    â€¢ Audit logging via CloudTrail
    â€¢ No secrets in code or .env files
    â€¢ Secrets cached locally for performance
```

**Secret Structure:**
```json
{
  "ai-infrastructure/anthropic-api-key": "sk-ant-...",
  "ai-infrastructure/openai-api-key": "sk-...",
  "ai-infrastructure/postgres": {
    "username": "ai_infra",
    "password": "...",
    "host": "localhost",
    "port": 5432,
    "database": "ai_infrastructure"
  },
  "ai-infrastructure/redis-password": "...",
  "ai-infrastructure/jwt-secret": "...",
  "ai-infrastructure/cloudflare-token": "...",
  "ai-infrastructure/github-pat": "ghp_..."
}
```

**Python Integration:**
```python
# packages/core/src/ai_core/secrets.py
import boto3
from functools import lru_cache

class SecretsManager:
    def __init__(self, region: str = "us-east-1", prefix: str = "ai-infrastructure/"):
        self.client = boto3.client("secretsmanager", region_name=region)
        self.prefix = prefix

    @lru_cache(maxsize=100)
    def get_secret(self, name: str) -> str:
        """Retrieve secret with caching."""
        response = self.client.get_secret_value(SecretId=f"{self.prefix}{name}")
        return response["SecretString"]

    def get_api_keys(self) -> dict:
        """Load all API keys at startup."""
        return {
            "anthropic": self.get_secret("anthropic-api-key"),
            "openai": self.get_secret("openai-api-key"),
            "cloudflare": self.get_secret("cloudflare-token"),
            "github": self.get_secret("github-pat"),
        }
```

### Cloudflare Integration (Paid Account)

Cloudflare provides DNS management, CDN, DDoS protection, SSL certificates, and advanced features with your paid account.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLOUDFLARE INTEGRATION                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              INTERNET
                                  â”‚
                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       CLOUDFLARE        â”‚
                    â”‚                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚   DNS MANAGEMENT  â”‚  â”‚
                    â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
                    â”‚  â”‚  A     â†’ Server IPâ”‚  â”‚
                    â”‚  â”‚  CNAME â†’ Aliases  â”‚  â”‚
                    â”‚  â”‚  MX    â†’ Mail     â”‚  â”‚
                    â”‚  â”‚  TXT   â†’ Verify   â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚   CDN / CACHING   â”‚  â”‚
                    â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
                    â”‚  â”‚  Static assets    â”‚  â”‚
                    â”‚  â”‚  Edge locations   â”‚  â”‚
                    â”‚  â”‚  Compression      â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚  SECURITY LAYER   â”‚  â”‚
                    â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
                    â”‚  â”‚  DDoS protection  â”‚  â”‚
                    â”‚  â”‚  WAF rules        â”‚  â”‚
                    â”‚  â”‚  Bot management   â”‚  â”‚
                    â”‚  â”‚  Rate limiting    â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚   SSL/TLS         â”‚  â”‚
                    â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â”‚
                    â”‚  â”‚  Free certificatesâ”‚  â”‚
                    â”‚  â”‚  Full (strict)    â”‚  â”‚
                    â”‚  â”‚  Auto-renewal     â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                         YOUR SERVER
```

**Infrastructure Agent Cloudflare Tools:**
```python
# services/agents/infra_agent/src/infra_agent/tools/cloudflare.py
import httpx
from typing import Optional

class CloudflareTools:
    """Cloudflare API client using Global API Key (paid account)."""
    BASE_URL = "https://api.cloudflare.com/client/v4"

    def __init__(self, api_key: str, email: str, account_id: str):
        self.headers = {
            "X-Auth-Key": api_key,
            "X-Auth-Email": email,
            "Content-Type": "application/json"
        }
        self.account_id = account_id
        self._zones: dict[str, str] = {}  # domain -> zone_id mapping

    async def list_zones(self) -> list[dict]:
        """List all zones in the account."""
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.BASE_URL}/zones",
                headers=self.headers,
                params={"account.id": self.account_id}
            )
            data = response.json()
            for zone in data.get("result", []):
                self._zones[zone["name"]] = zone["id"]
            return data["result"]

    async def add_dns_record(self, zone_id: str, name: str, content: str,
                            type: str = "A", proxied: bool = True, ttl: int = 1):
        """Add a DNS record for a new domain."""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.BASE_URL}/zones/{zone_id}/dns_records",
                headers=self.headers,
                json={
                    "type": type, "name": name, "content": content,
                    "proxied": proxied, "ttl": ttl
                }
            )
            return response.json()

    async def create_zone(self, domain: str) -> dict:
        """Add a new domain/zone to the account."""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.BASE_URL}/zones",
                headers=self.headers,
                json={"name": domain, "account": {"id": self.account_id}}
            )
            return response.json()

    async def purge_cache(self, zone_id: str, files: list[str] = None):
        """Purge CDN cache for specific files or entire zone."""
        payload = {"purge_everything": True} if not files else {"files": files}
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.BASE_URL}/zones/{zone_id}/purge_cache",
                headers=self.headers,
                json=payload
            )
            return response.json()

    async def create_waf_rule(self, zone_id: str, expression: str,
                              action: str = "block", description: str = ""):
        """Create a WAF custom rule (paid feature)."""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.BASE_URL}/zones/{zone_id}/rulesets/phases/http_request_firewall_custom/entrypoint",
                headers=self.headers,
                json={
                    "rules": [{
                        "expression": expression,
                        "action": action,
                        "description": description
                    }]
                }
            )
            return response.json()

    async def get_analytics(self, zone_id: str, since: str = "-1440"):
        """Get traffic analytics for the zone."""
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.BASE_URL}/zones/{zone_id}/analytics/dashboard",
                headers=self.headers,
                params={"since": since}
            )
            return response.json()

    async def update_ssl_settings(self, zone_id: str, mode: str = "full"):
        """Update SSL/TLS encryption mode (off, flexible, full, strict)."""
        async with httpx.AsyncClient() as client:
            response = await client.patch(
                f"{self.BASE_URL}/zones/{zone_id}/settings/ssl",
                headers=self.headers,
                json={"value": mode}
            )
            return response.json()

    async def enable_always_https(self, zone_id: str, enabled: bool = True):
        """Enable Always Use HTTPS."""
        async with httpx.AsyncClient() as client:
            response = await client.patch(
                f"{self.BASE_URL}/zones/{zone_id}/settings/always_use_https",
                headers=self.headers,
                json={"value": "on" if enabled else "off"}
            )
            return response.json()
```

**Agent Commands via Cloudflare (Paid Features):**
- Create new zones/domains in account
- Add/remove DNS records (A, AAAA, CNAME, MX, TXT)
- Purge CDN cache after deployments
- Enable/disable proxying for maintenance
- Create WAF custom rules for security
- Configure SSL/TLS modes (Full Strict recommended)
- Enable Always HTTPS redirect
- Set up Page Rules for URL routing
- Monitor traffic analytics and threats
- Configure rate limiting rules
- Manage Workers (serverless functions)
- Set up Load Balancing (if subscribed)

### GitHub Integration

GitHub provides version control, backup, and collaboration through PAT (Personal Access Token).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GITHUB INTEGRATION                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    AI INFRASTRUCTURE                              GITHUB
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”€â”€â”€â”€â”€â”€â”€â”€

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   /workspace        â”‚   git push      â”‚  Main Repository    â”‚
    â”‚   (Active code)     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  AI-Infrastructure  â”‚
    â”‚                     â”‚                 â”‚                     â”‚
    â”‚   - Services        â”‚                 â”‚  - Full codebase    â”‚
    â”‚   - Packages        â”‚                 â”‚  - Agent prompts    â”‚
    â”‚   - Config          â”‚                 â”‚  - Configurations   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PAI MEMORY        â”‚   Scheduled     â”‚  Backup Repository  â”‚
    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚   Backup        â”‚  ai-infra-backup    â”‚
    â”‚                     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                     â”‚
    â”‚   - Learning/       â”‚   (Daily)       â”‚  - Memory snapshots â”‚
    â”‚   - Signals/        â”‚                 â”‚  - Learning history â”‚
    â”‚   - Work/           â”‚                 â”‚  - Configuration    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   CONFIGURATIONS    â”‚   Sync          â”‚  Config Repository  â”‚
    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  ai-infra-config    â”‚
    â”‚                     â”‚                 â”‚                     â”‚
    â”‚   - agents.yaml     â”‚                 â”‚  - Versioned config â”‚
    â”‚   - domains.yaml    â”‚                 â”‚  - Change tracking  â”‚
    â”‚   - TELOS/          â”‚                 â”‚  - Rollback support â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USE CASES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. CODE BACKUP:     Daily automated backup of all code changes
2. MEMORY BACKUP:   Weekly backup of PAI memory and learnings
3. CONFIG SYNC:     Bi-directional sync of configurations
4. AGENT PROMPTS:   Version control for agent system prompts
5. COLLABORATION:   Multiple users can contribute improvements
6. ROLLBACK:        Restore previous versions if issues occur
```

**GitHub Tools for Agents:**
```python
# packages/core/src/ai_core/github.py
import httpx
import base64
from datetime import datetime

class GitHubClient:
    BASE_URL = "https://api.github.com"

    def __init__(self, token: str, owner: str, repo: str):
        self.headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "application/vnd.github.v3+json"
        }
        self.owner = owner
        self.repo = repo

    async def backup_file(self, path: str, content: str, message: str = None):
        """Backup a file to GitHub repository."""
        message = message or f"Backup: {path} at {datetime.utcnow().isoformat()}"
        encoded = base64.b64encode(content.encode()).decode()

        # Get current file SHA if exists (for update)
        sha = await self._get_file_sha(path)

        payload = {
            "message": message,
            "content": encoded,
            "branch": "main"
        }
        if sha:
            payload["sha"] = sha

        async with httpx.AsyncClient() as client:
            response = await client.put(
                f"{self.BASE_URL}/repos/{self.owner}/{self.repo}/contents/{path}",
                headers=self.headers,
                json=payload
            )
            return response.json()

    async def backup_memory(self, memory_dir: str):
        """Backup entire PAI memory directory."""
        # Tar and upload memory directory
        pass

    async def create_release(self, tag: str, name: str, body: str):
        """Create a release for version tracking."""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.BASE_URL}/repos/{self.owner}/{self.repo}/releases",
                headers=self.headers,
                json={"tag_name": tag, "name": name, "body": body}
            )
            return response.json()

    async def sync_config(self, local_path: str, remote_path: str):
        """Bi-directional sync of configuration files."""
        pass
```

**Automated Backup Schedule:**
```yaml
# config/backup.yaml
schedules:
  code_backup:
    cron: "0 2 * * *"        # Daily at 2 AM
    type: full
    target: AI-Infrastructure

  memory_backup:
    cron: "0 3 * * 0"        # Weekly on Sunday at 3 AM
    type: incremental
    target: ai-infra-backup
    paths:
      - pai/MEMORY/Learning
      - pai/MEMORY/Signals

  config_sync:
    cron: "*/30 * * * *"     # Every 30 minutes
    type: bidirectional
    target: ai-infra-config
    paths:
      - config/agents.yaml
      - config/domains.yaml
      - pai/TELOS/
```

---

## Advanced Features

### Agent Isolation with Namespaced Workspaces

Each agent has isolated scratch space to prevent conflicts while sharing the main codebase.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      WORKSPACE ISOLATION                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

/workspace/                           # Shared codebase
â”œâ”€â”€ services/                         # Read-only for most agents
â”œâ”€â”€ packages/
â”œâ”€â”€ web/
â””â”€â”€ .agent-scratch/                   # Per-agent isolated workspaces
    â”œâ”€â”€ supervisor/
    â”‚   â”œâ”€â”€ working/                  # Current task files
    â”‚   â”œâ”€â”€ temp/                     # Temporary files
    â”‚   â””â”€â”€ cache/                    # Agent-specific cache
    â”œâ”€â”€ code_agent/
    â”‚   â”œâ”€â”€ working/
    â”‚   â”œâ”€â”€ temp/
    â”‚   â”œâ”€â”€ cache/
    â”‚   â””â”€â”€ git-worktrees/           # Isolated git operations
    â”œâ”€â”€ data_agent/
    â”‚   â”œâ”€â”€ working/
    â”‚   â”œâ”€â”€ temp/
    â”‚   â”œâ”€â”€ exports/                  # Data exports
    â”‚   â””â”€â”€ cache/
    â”œâ”€â”€ infra_agent/
    â”‚   â”œâ”€â”€ working/
    â”‚   â”œâ”€â”€ temp/
    â”‚   â””â”€â”€ backups/                  # Config backups before changes
    â”œâ”€â”€ research_agent/
    â”‚   â”œâ”€â”€ working/
    â”‚   â”œâ”€â”€ temp/
    â”‚   â”œâ”€â”€ downloads/                # Downloaded resources
    â”‚   â””â”€â”€ summaries/                # Generated summaries
    â””â”€â”€ qa_agent/
        â”œâ”€â”€ working/
        â”œâ”€â”€ temp/
        â”œâ”€â”€ reports/                  # Test reports
        â””â”€â”€ coverage/                 # Coverage data
```

```python
# packages/core/src/ai_core/workspace.py
from pathlib import Path
from typing import Literal

class AgentWorkspace:
    """Manages isolated workspace for each agent."""

    def __init__(self, agent_id: str, base_path: Path = Path("/workspace")):
        self.agent_id = agent_id
        self.base_path = base_path
        self.scratch_path = base_path / ".agent-scratch" / agent_id

        # Create workspace directories
        for subdir in ["working", "temp", "cache"]:
            (self.scratch_path / subdir).mkdir(parents=True, exist_ok=True)

    @property
    def working_dir(self) -> Path:
        return self.scratch_path / "working"

    @property
    def temp_dir(self) -> Path:
        return self.scratch_path / "temp"

    def can_write(self, path: Path) -> bool:
        """Check if agent can write to path."""
        # Agents can always write to their scratch space
        if path.is_relative_to(self.scratch_path):
            return True
        # Check permission level for other paths
        return self._check_permissions(path)

    def cleanup_temp(self, max_age_hours: int = 24):
        """Clean up old temporary files."""
        # Implementation
        pass
```

### Task DAG with Priority & Dependencies

Replace simple pub/sub with a proper Directed Acyclic Graph for task orchestration.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TASK DAG SYSTEM                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example: "Build and deploy a new feature"

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   User Request  â”‚
                    â”‚   Priority: 10  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Supervisor    â”‚
                    â”‚   Decompose     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task A        â”‚   â”‚ Task B        â”‚   â”‚ Task C        â”‚
â”‚ Research API  â”‚   â”‚ Design Schema â”‚   â”‚ Write Tests   â”‚
â”‚ Agent: researchâ”‚   â”‚ Agent: data   â”‚   â”‚ Agent: qa     â”‚
â”‚ Priority: 8   â”‚   â”‚ Priority: 8   â”‚   â”‚ Priority: 7   â”‚
â”‚ Deps: none    â”‚   â”‚ Deps: none    â”‚   â”‚ Deps: none    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
                  â”‚                             â”‚
                  â–¼                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
        â”‚ Task D        â”‚                       â”‚
        â”‚ Implement API â”‚                       â”‚
        â”‚ Agent: code   â”‚                       â”‚
        â”‚ Priority: 9   â”‚                       â”‚
        â”‚ Deps: [A, B]  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        (waits for D)
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Task E        â”‚
        â”‚ Run Tests     â”‚
        â”‚ Agent: qa     â”‚
        â”‚ Priority: 9   â”‚
        â”‚ Deps: [C, D]  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Task F        â”‚
        â”‚ Deploy        â”‚
        â”‚ Agent: infra  â”‚
        â”‚ Priority: 10  â”‚
        â”‚ Deps: [E]     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# packages/messaging/src/ai_messaging/task_dag.py
from dataclasses import dataclass, field
from enum import Enum
from typing import Optional
from uuid import UUID, uuid4
import asyncio
import heapq

class TaskState(Enum):
    PENDING = "pending"
    READY = "ready"           # Dependencies satisfied
    ASSIGNED = "assigned"
    IN_PROGRESS = "in_progress"
    BLOCKED = "blocked"       # Waiting for dependency
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class Task:
    id: UUID = field(default_factory=uuid4)
    name: str = ""
    description: str = ""
    agent_type: str = ""
    priority: int = 5         # 1-10, higher = more urgent
    state: TaskState = TaskState.PENDING
    depends_on: list[UUID] = field(default_factory=list)
    created_at: float = field(default_factory=lambda: asyncio.get_event_loop().time())
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    result: Optional[dict] = None
    error: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    timeout_seconds: int = 300

    def __lt__(self, other):
        # For priority queue: higher priority first, then older tasks
        return (-self.priority, self.created_at) < (-other.priority, other.created_at)

class TaskDAG:
    """Directed Acyclic Graph for task dependencies."""

    def __init__(self, redis_client):
        self.redis = redis_client
        self.tasks: dict[UUID, Task] = {}
        self.dependents: dict[UUID, set[UUID]] = {}  # task -> tasks that depend on it
        self.ready_queue: list[Task] = []  # Priority queue of ready tasks

    async def submit(self, task: Task) -> UUID:
        """Submit a task to the DAG."""
        self.tasks[task.id] = task

        # Track reverse dependencies
        for dep_id in task.depends_on:
            if dep_id not in self.dependents:
                self.dependents[dep_id] = set()
            self.dependents[dep_id].add(task.id)

        # Check if ready immediately
        if self._dependencies_satisfied(task):
            task.state = TaskState.READY
            heapq.heappush(self.ready_queue, task)
            await self._notify_ready(task)
        else:
            task.state = TaskState.BLOCKED

        await self._persist_task(task)
        return task.id

    async def get_ready_tasks(self, agent_type: str, limit: int = 5) -> list[Task]:
        """Get tasks ready for a specific agent type."""
        ready = []
        for task in self.ready_queue:
            if task.agent_type == agent_type and task.state == TaskState.READY:
                ready.append(task)
                if len(ready) >= limit:
                    break
        return ready

    async def complete_task(self, task_id: UUID, result: dict):
        """Mark task as completed and unblock dependents."""
        task = self.tasks[task_id]
        task.state = TaskState.COMPLETED
        task.result = result
        task.completed_at = asyncio.get_event_loop().time()

        # Check if any dependent tasks are now ready
        for dependent_id in self.dependents.get(task_id, []):
            dependent = self.tasks[dependent_id]
            if self._dependencies_satisfied(dependent):
                dependent.state = TaskState.READY
                heapq.heappush(self.ready_queue, dependent)
                await self._notify_ready(dependent)

        await self._persist_task(task)

    async def fail_task(self, task_id: UUID, error: str):
        """Mark task as failed, potentially retry."""
        task = self.tasks[task_id]
        task.retry_count += 1

        if task.retry_count < task.max_retries:
            task.state = TaskState.READY
            heapq.heappush(self.ready_queue, task)
        else:
            task.state = TaskState.FAILED
            task.error = error
            # Cancel all dependent tasks
            await self._cancel_dependents(task_id)

        await self._persist_task(task)

    def _dependencies_satisfied(self, task: Task) -> bool:
        """Check if all dependencies are completed."""
        for dep_id in task.depends_on:
            dep = self.tasks.get(dep_id)
            if not dep or dep.state != TaskState.COMPLETED:
                return False
        return True

    async def _notify_ready(self, task: Task):
        """Notify agent that a task is ready."""
        await self.redis.publish(f"agent:{task.agent_type}:tasks", task.id.hex)

    async def _cancel_dependents(self, task_id: UUID):
        """Recursively cancel all dependent tasks."""
        for dependent_id in self.dependents.get(task_id, []):
            dependent = self.tasks[dependent_id]
            dependent.state = TaskState.CANCELLED
            await self._cancel_dependents(dependent_id)

    async def _persist_task(self, task: Task):
        """Persist task state to Redis."""
        await self.redis.hset(f"task:{task.id}", mapping=task.__dict__)
```

### Agent Hot-Reload

Update agent prompts and tools without restarting.

```python
# packages/core/src/ai_core/hot_reload.py
import asyncio
import hashlib
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class AgentHotReloader:
    """Watches for changes and reloads agent configuration."""

    def __init__(self, agent, config_paths: list[Path]):
        self.agent = agent
        self.config_paths = config_paths
        self.file_hashes: dict[Path, str] = {}
        self.observer = Observer()

    def start(self):
        """Start watching for file changes."""
        handler = ReloadHandler(self)
        for path in self.config_paths:
            self.observer.schedule(handler, str(path.parent), recursive=False)
            self.file_hashes[path] = self._hash_file(path)
        self.observer.start()

    async def check_and_reload(self):
        """Check for changes and reload if needed."""
        for path in self.config_paths:
            current_hash = self._hash_file(path)
            if current_hash != self.file_hashes.get(path):
                self.file_hashes[path] = current_hash
                await self._reload_component(path)

    async def _reload_component(self, path: Path):
        """Reload specific component based on file type."""
        if path.name == "AGENT.md":
            await self._reload_system_prompt(path)
        elif path.suffix == ".py" and "tools" in str(path):
            await self._reload_tools(path)
        elif path.suffix in [".yaml", ".yml"]:
            await self._reload_config(path)

    async def _reload_system_prompt(self, path: Path):
        """Reload system prompt without losing conversation."""
        new_prompt = path.read_text()
        self.agent.system_prompt = new_prompt
        self.agent.logger.info(f"Reloaded system prompt from {path}")

    async def _reload_tools(self, path: Path):
        """Reload tool definitions."""
        # Re-import tools module
        import importlib
        module_name = str(path.with_suffix('')).replace('/', '.')
        module = importlib.import_module(module_name)
        importlib.reload(module)
        self.agent.tools = self.agent.discover_tools()
        self.agent.logger.info(f"Reloaded tools from {path}")

    def _hash_file(self, path: Path) -> str:
        return hashlib.md5(path.read_bytes()).hexdigest()

class ReloadHandler(FileSystemEventHandler):
    def __init__(self, reloader: AgentHotReloader):
        self.reloader = reloader

    def on_modified(self, event):
        asyncio.create_task(self.reloader.check_and_reload())
```

### Command Allowlist/Blocklist Security

```yaml
# config/agent_permissions.yaml
permissions:
  default: &default_permissions
    max_file_size_mb: 50
    max_execution_time_seconds: 300
    blocked_patterns:
      - "rm -rf /"
      - "rm -rf /*"
      - ":(){ :|:& };:"          # Fork bomb
      - "> /dev/sda"
      - "mkfs"
      - "dd if="
      - "chmod -R 777 /"
      - "chown -R"
    blocked_commands:
      - "shutdown"
      - "reboot"
      - "init"
      - "poweroff"
      - "halt"

  supervisor:
    <<: *default_permissions
    allowed_commands: "*"        # Full access
    requires_approval:
      - "rm -rf"
      - "DROP DATABASE"
      - "systemctl stop"

  code_agent:
    <<: *default_permissions
    allowed_commands:
      - git
      - npm
      - npx
      - yarn
      - pip
      - pip3
      - python
      - python3
      - node
      - pytest
      - cargo
      - go
      - make
    allowed_paths:
      - /workspace
      - /tmp
    denied_paths:
      - /etc
      - /var
      - /root

  data_agent:
    <<: *default_permissions
    allowed_commands:
      - psql
      - redis-cli
      - python
      - pip
    allowed_sql_operations:
      - SELECT
      - INSERT
      - UPDATE
      - CREATE TABLE
      - CREATE INDEX
    denied_sql_operations:
      - DROP DATABASE
      - TRUNCATE
      - DELETE FROM  # Without WHERE clause
    requires_approval:
      - DROP TABLE
      - ALTER TABLE

  infra_agent:
    <<: *default_permissions
    allowed_commands:
      - docker
      - docker-compose
      - nginx
      - certbot
      - systemctl
      - journalctl
      - htop
      - df
      - du
      - free
      - ufw
    allowed_systemctl_units:
      - nginx
      - docker
      - redis
      - postgresql
      - ai-infrastructure
    requires_approval:
      - systemctl stop
      - systemctl disable
      - docker rm
      - docker system prune
      - ufw disable

  research_agent:
    <<: *default_permissions
    allowed_commands:
      - curl
      - wget
      - python
    network_allowlist:
      - "*.github.com"
      - "*.stackoverflow.com"
      - "*.wikipedia.org"
      - "api.anthropic.com"
      - "api.openai.com"
    max_download_size_mb: 100

  qa_agent:
    <<: *default_permissions
    allowed_commands:
      - pytest
      - npm
      - node
      - python
      - coverage
      - bandit         # Security scanner
      - safety         # Dependency checker
      - trivy          # Container scanner
```

```python
# packages/core/src/ai_core/permissions.py
import re
import shlex
from pathlib import Path
from typing import Optional
import yaml

class PermissionDenied(Exception):
    """Raised when an agent attempts an unauthorized action."""
    pass

class CommandValidator:
    """Validates commands against agent permissions."""

    def __init__(self, config_path: Path = Path("config/agent_permissions.yaml")):
        with open(config_path) as f:
            self.config = yaml.safe_load(f)

    def validate_command(self, agent_id: str, command: str) -> tuple[bool, Optional[str]]:
        """
        Validate a command for an agent.
        Returns (allowed, reason) tuple.
        """
        permissions = self.config["permissions"].get(agent_id, self.config["permissions"]["default"])

        # Check blocked patterns first
        for pattern in permissions.get("blocked_patterns", []):
            if re.search(pattern, command, re.IGNORECASE):
                return False, f"Command matches blocked pattern: {pattern}"

        # Parse command
        try:
            parts = shlex.split(command)
            base_command = parts[0] if parts else ""
        except ValueError:
            return False, "Invalid command syntax"

        # Check blocked commands
        if base_command in permissions.get("blocked_commands", []):
            return False, f"Command '{base_command}' is blocked"

        # Check allowed commands
        allowed = permissions.get("allowed_commands", [])
        if allowed != "*" and base_command not in allowed:
            return False, f"Command '{base_command}' is not in allowlist"

        # Check if requires approval
        for pattern in permissions.get("requires_approval", []):
            if pattern in command:
                return "approval_required", f"Command requires human approval: {pattern}"

        return True, None

    def validate_path(self, agent_id: str, path: Path, operation: str = "read") -> tuple[bool, Optional[str]]:
        """Validate file path access for an agent."""
        permissions = self.config["permissions"].get(agent_id, {})

        # Check denied paths
        for denied in permissions.get("denied_paths", []):
            if path.is_relative_to(denied):
                return False, f"Access to {denied} is denied"

        # Check allowed paths for write operations
        if operation == "write":
            allowed = permissions.get("allowed_paths", [])
            if not any(path.is_relative_to(a) for a in allowed):
                return False, f"Write access not allowed to {path}"

        return True, None

    def validate_sql(self, agent_id: str, query: str) -> tuple[bool, Optional[str]]:
        """Validate SQL query for an agent."""
        permissions = self.config["permissions"].get(agent_id, {})
        query_upper = query.upper().strip()

        # Check denied operations
        for denied in permissions.get("denied_sql_operations", []):
            if query_upper.startswith(denied):
                return False, f"SQL operation '{denied}' is not allowed"

        # Check allowed operations
        allowed = permissions.get("allowed_sql_operations", [])
        if allowed:
            if not any(query_upper.startswith(op) for op in allowed):
                return False, "SQL operation not in allowlist"

        return True, None
```

### Audit Trail System

```python
# packages/core/src/ai_core/audit.py
import hashlib
import json
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Optional, Any
from uuid import UUID, uuid4
import asyncio

class AuditEventType(Enum):
    COMMAND_EXECUTED = "command_executed"
    FILE_READ = "file_read"
    FILE_WRITE = "file_write"
    FILE_DELETE = "file_delete"
    API_CALL = "api_call"
    TASK_STARTED = "task_started"
    TASK_COMPLETED = "task_completed"
    TASK_FAILED = "task_failed"
    PERMISSION_DENIED = "permission_denied"
    PERMISSION_ESCALATION = "permission_escalation"
    AGENT_STARTED = "agent_started"
    AGENT_STOPPED = "agent_stopped"
    USER_LOGIN = "user_login"
    USER_LOGOUT = "user_logout"
    CONFIG_CHANGED = "config_changed"
    SECRET_ACCESSED = "secret_accessed"

@dataclass
class AuditEvent:
    id: UUID
    timestamp: datetime
    event_type: AuditEventType
    agent_id: str
    user_id: Optional[str]
    session_id: Optional[str]
    action: str
    target: str                    # File path, command, API endpoint
    details: dict
    outcome: str                   # success, failure, denied
    ip_address: Optional[str]
    previous_hash: Optional[str]   # For tamper detection
    hash: Optional[str] = None

    def compute_hash(self) -> str:
        """Compute hash for tamper detection."""
        data = {
            "id": str(self.id),
            "timestamp": self.timestamp.isoformat(),
            "event_type": self.event_type.value,
            "agent_id": self.agent_id,
            "action": self.action,
            "target": self.target,
            "outcome": self.outcome,
            "previous_hash": self.previous_hash,
        }
        return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()

class AuditLog:
    """Tamper-evident audit logging system."""

    def __init__(self, log_path: Path, redis_client=None, s3_client=None):
        self.log_path = log_path
        self.redis = redis_client
        self.s3 = s3_client
        self.last_hash: Optional[str] = None
        self._load_last_hash()

    def _load_last_hash(self):
        """Load the last hash from the log."""
        if self.log_path.exists():
            with open(self.log_path, 'rb') as f:
                f.seek(0, 2)  # End of file
                if f.tell() > 0:
                    f.seek(max(0, f.tell() - 4096))
                    lines = f.read().decode().strip().split('\n')
                    if lines:
                        last_entry = json.loads(lines[-1])
                        self.last_hash = last_entry.get("hash")

    async def log(self, event: AuditEvent):
        """Log an audit event with tamper detection."""
        event.previous_hash = self.last_hash
        event.hash = event.compute_hash()
        self.last_hash = event.hash

        entry = asdict(event)
        entry["timestamp"] = event.timestamp.isoformat()
        entry["event_type"] = event.event_type.value
        entry["id"] = str(event.id)

        # Write to local log (append-only)
        with open(self.log_path, 'a') as f:
            f.write(json.dumps(entry) + '\n')

        # Also send to Redis for real-time monitoring
        if self.redis:
            await self.redis.xadd("audit:stream", entry)

        # Ship to S3 for long-term storage (batched)
        if self.s3:
            await self._queue_for_s3(entry)

    async def verify_integrity(self) -> tuple[bool, list[int]]:
        """Verify the audit log hasn't been tampered with."""
        corrupted_lines = []
        previous_hash = None

        with open(self.log_path, 'r') as f:
            for i, line in enumerate(f):
                entry = json.loads(line)
                if entry.get("previous_hash") != previous_hash:
                    corrupted_lines.append(i)

                # Recompute hash
                event = AuditEvent(
                    id=UUID(entry["id"]),
                    timestamp=datetime.fromisoformat(entry["timestamp"]),
                    event_type=AuditEventType(entry["event_type"]),
                    agent_id=entry["agent_id"],
                    user_id=entry.get("user_id"),
                    session_id=entry.get("session_id"),
                    action=entry["action"],
                    target=entry["target"],
                    details=entry["details"],
                    outcome=entry["outcome"],
                    ip_address=entry.get("ip_address"),
                    previous_hash=entry.get("previous_hash"),
                )
                expected_hash = event.compute_hash()
                if entry.get("hash") != expected_hash:
                    corrupted_lines.append(i)

                previous_hash = entry.get("hash")

        return len(corrupted_lines) == 0, corrupted_lines

# Decorator for automatic audit logging
def audited(event_type: AuditEventType):
    def decorator(func):
        async def wrapper(self, *args, **kwargs):
            event = AuditEvent(
                id=uuid4(),
                timestamp=datetime.utcnow(),
                event_type=event_type,
                agent_id=self.agent_id,
                user_id=getattr(self, 'user_id', None),
                session_id=getattr(self, 'session_id', None),
                action=func.__name__,
                target=str(args[0]) if args else "",
                details={"args": str(args), "kwargs": str(kwargs)},
                outcome="pending",
                ip_address=None,
                previous_hash=None,
            )
            try:
                result = await func(self, *args, **kwargs)
                event.outcome = "success"
                return result
            except Exception as e:
                event.outcome = "failure"
                event.details["error"] = str(e)
                raise
            finally:
                await self.audit_log.log(event)
        return wrapper
    return decorator
```

### Network Egress Filtering

```yaml
# config/network_policies.yaml
network_policies:
  default:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "api.openai.com:443"
      deny:
        - "*:22"                  # No SSH out
        - "*:23"                  # No Telnet
        - "*.onion:*"            # No Tor
    max_connections: 100
    rate_limit_requests_per_minute: 1000

  code_agent:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "github.com:443"
        - "api.github.com:443"
        - "*.githubusercontent.com:443"
        - "pypi.org:443"
        - "files.pythonhosted.org:443"
        - "registry.npmjs.org:443"
        - "registry.yarnpkg.com:443"
        - "crates.io:443"
        - "proxy.golang.org:443"

  data_agent:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "localhost:5432"       # PostgreSQL
        - "localhost:6379"       # Redis
        - "localhost:6333"       # Qdrant

  infra_agent:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "api.cloudflare.com:443"
        - "api.github.com:443"
        - "registry.docker.io:443"
        - "*.docker.com:443"
        - "acme-v02.api.letsencrypt.org:443"
        - "secretsmanager.*.amazonaws.com:443"

  research_agent:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "api.openai.com:443"
        - "*:443"                # Needs broad web access
      deny:
        - "*.local:*"
        - "10.*:*"
        - "192.168.*:*"
        - "172.16.*:*"
    rate_limit_requests_per_minute: 100
    max_download_size_mb: 100

  qa_agent:
    egress:
      allow:
        - "api.anthropic.com:443"
        - "localhost:*"          # For testing local services
```

```python
# packages/core/src/ai_core/network.py
import fnmatch
import asyncio
from dataclasses import dataclass
from typing import Optional
import yaml

@dataclass
class NetworkPolicy:
    allow: list[str]
    deny: list[str]
    rate_limit: int
    max_connections: int

class NetworkFilter:
    """Filter outbound network connections per agent."""

    def __init__(self, config_path: str = "config/network_policies.yaml"):
        with open(config_path) as f:
            self.config = yaml.safe_load(f)
        self.connection_counts: dict[str, int] = {}
        self.request_counts: dict[str, list[float]] = {}

    def can_connect(self, agent_id: str, host: str, port: int) -> tuple[bool, Optional[str]]:
        """Check if agent can connect to host:port."""
        policy = self.config["network_policies"].get(
            agent_id,
            self.config["network_policies"]["default"]
        )

        target = f"{host}:{port}"

        # Check deny list first
        for pattern in policy.get("egress", {}).get("deny", []):
            if fnmatch.fnmatch(target, pattern):
                return False, f"Connection to {target} denied by policy"

        # Check allow list
        for pattern in policy.get("egress", {}).get("allow", []):
            if fnmatch.fnmatch(target, pattern):
                # Check rate limit
                if not self._check_rate_limit(agent_id, policy):
                    return False, "Rate limit exceeded"
                # Check connection limit
                if not self._check_connection_limit(agent_id, policy):
                    return False, "Connection limit exceeded"
                return True, None

        return False, f"Connection to {target} not in allowlist"

    def _check_rate_limit(self, agent_id: str, policy: dict) -> bool:
        """Check if agent is within rate limit."""
        limit = policy.get("rate_limit_requests_per_minute", 1000)
        now = asyncio.get_event_loop().time()

        if agent_id not in self.request_counts:
            self.request_counts[agent_id] = []

        # Remove old entries
        self.request_counts[agent_id] = [
            t for t in self.request_counts[agent_id]
            if now - t < 60
        ]

        if len(self.request_counts[agent_id]) >= limit:
            return False

        self.request_counts[agent_id].append(now)
        return True
```

### Observability Stack

```yaml
# docker-compose.observability.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-prometheus
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./infrastructure/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    ports:
      - "9090:9090"
    networks:
      - ai-network

  grafana:
    image: grafana/grafana:latest
    container_name: ai-grafana
    volumes:
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning
      - ./infrastructure/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3001:3000"
    networks:
      - ai-network

  loki:
    image: grafana/loki:latest
    container_name: ai-loki
    volumes:
      - ./infrastructure/loki/loki-config.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    ports:
      - "3100:3100"
    networks:
      - ai-network

  promtail:
    image: grafana/promtail:latest
    container_name: ai-promtail
    volumes:
      - ./infrastructure/promtail/promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - ./logs:/app/logs:ro
    networks:
      - ai-network

volumes:
  prometheus_data:
  grafana_data:
  loki_data:

networks:
  ai-network:
    external: true
```

```python
# packages/core/src/ai_core/observability.py
from prometheus_client import Counter, Histogram, Gauge, Info, start_http_server
from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
import structlog

# Initialize tracing
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer("ai-infrastructure")

# Metrics
TASK_DURATION = Histogram(
    'ai_task_duration_seconds',
    'Time spent processing tasks',
    ['agent_type', 'task_type', 'status'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0]
)

TASK_COUNTER = Counter(
    'ai_tasks_total',
    'Total number of tasks processed',
    ['agent_type', 'task_type', 'status']
)

AGENT_STATUS = Gauge(
    'ai_agent_status',
    'Current agent status (1=healthy, 0=unhealthy)',
    ['agent_id', 'agent_type']
)

ACTIVE_TASKS = Gauge(
    'ai_active_tasks',
    'Number of currently active tasks',
    ['agent_type']
)

TOKEN_USAGE = Counter(
    'ai_tokens_total',
    'Total tokens used',
    ['agent_type', 'model', 'direction']  # direction: input/output
)

MEMORY_RETRIEVALS = Counter(
    'ai_memory_retrievals_total',
    'Number of memory/knowledge retrievals',
    ['agent_type', 'memory_type', 'hit']  # hit: true/false
)

API_LATENCY = Histogram(
    'ai_api_latency_seconds',
    'External API call latency',
    ['service', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

ERROR_COUNTER = Counter(
    'ai_errors_total',
    'Total number of errors',
    ['agent_type', 'error_type']
)

# Structured logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
)

def get_logger(name: str):
    return structlog.get_logger(name)

class MetricsCollector:
    """Collects and exposes metrics for an agent."""

    def __init__(self, agent_id: str, agent_type: str, port: int = 8000):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.logger = get_logger(f"metrics.{agent_id}")
        start_http_server(port)

    def record_task(self, task_type: str, duration: float, status: str):
        TASK_DURATION.labels(
            agent_type=self.agent_type,
            task_type=task_type,
            status=status
        ).observe(duration)

        TASK_COUNTER.labels(
            agent_type=self.agent_type,
            task_type=task_type,
            status=status
        ).inc()

    def record_tokens(self, model: str, input_tokens: int, output_tokens: int):
        TOKEN_USAGE.labels(
            agent_type=self.agent_type,
            model=model,
            direction="input"
        ).inc(input_tokens)

        TOKEN_USAGE.labels(
            agent_type=self.agent_type,
            model=model,
            direction="output"
        ).inc(output_tokens)

    def set_healthy(self, healthy: bool):
        AGENT_STATUS.labels(
            agent_id=self.agent_id,
            agent_type=self.agent_type
        ).set(1 if healthy else 0)
```

### Health Check Dashboard

```python
# packages/core/src/ai_core/health.py
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Optional, Literal
from collections import deque
import asyncio

@dataclass
class AgentHealth:
    agent_id: str
    agent_type: str
    status: Literal["healthy", "degraded", "unhealthy", "offline"]
    last_heartbeat: datetime
    last_task_completed: Optional[datetime]
    tasks_completed_last_hour: int
    tasks_failed_last_hour: int
    avg_response_time_ms: float
    error_rate_percent: float
    memory_usage_mb: float
    cpu_percent: float
    current_task: Optional[str]
    queue_depth: int
    uptime_seconds: float

class HealthMonitor:
    """Monitors health of all agents."""

    def __init__(self, redis_client):
        self.redis = redis_client
        self.agents: dict[str, AgentHealth] = {}
        self.response_times: dict[str, deque] = {}  # Rolling window
        self.heartbeat_timeout = timedelta(seconds=30)

    async def record_heartbeat(self, agent_id: str, metrics: dict):
        """Record heartbeat from an agent."""
        if agent_id not in self.agents:
            self.agents[agent_id] = AgentHealth(
                agent_id=agent_id,
                agent_type=metrics.get("agent_type", "unknown"),
                status="healthy",
                last_heartbeat=datetime.utcnow(),
                last_task_completed=None,
                tasks_completed_last_hour=0,
                tasks_failed_last_hour=0,
                avg_response_time_ms=0,
                error_rate_percent=0,
                memory_usage_mb=metrics.get("memory_mb", 0),
                cpu_percent=metrics.get("cpu_percent", 0),
                current_task=metrics.get("current_task"),
                queue_depth=metrics.get("queue_depth", 0),
                uptime_seconds=metrics.get("uptime_seconds", 0),
            )
        else:
            health = self.agents[agent_id]
            health.last_heartbeat = datetime.utcnow()
            health.memory_usage_mb = metrics.get("memory_mb", health.memory_usage_mb)
            health.cpu_percent = metrics.get("cpu_percent", health.cpu_percent)
            health.current_task = metrics.get("current_task")
            health.queue_depth = metrics.get("queue_depth", 0)

        await self._update_status(agent_id)

    async def record_task_completion(self, agent_id: str, duration_ms: float, success: bool):
        """Record task completion metrics."""
        if agent_id not in self.response_times:
            self.response_times[agent_id] = deque(maxlen=100)

        self.response_times[agent_id].append((duration_ms, success))

        health = self.agents.get(agent_id)
        if health:
            health.last_task_completed = datetime.utcnow()
            if success:
                health.tasks_completed_last_hour += 1
            else:
                health.tasks_failed_last_hour += 1

            # Recalculate averages
            times = self.response_times[agent_id]
            health.avg_response_time_ms = sum(t[0] for t in times) / len(times)
            failures = sum(1 for t in times if not t[1])
            health.error_rate_percent = (failures / len(times)) * 100

        await self._update_status(agent_id)

    async def _update_status(self, agent_id: str):
        """Update agent status based on metrics."""
        health = self.agents.get(agent_id)
        if not health:
            return

        now = datetime.utcnow()

        # Check heartbeat
        if now - health.last_heartbeat > self.heartbeat_timeout:
            health.status = "offline"
        elif health.error_rate_percent > 50:
            health.status = "unhealthy"
        elif health.error_rate_percent > 20 or health.avg_response_time_ms > 30000:
            health.status = "degraded"
        else:
            health.status = "healthy"

        # Publish status update
        await self.redis.publish("health:updates", {
            "agent_id": agent_id,
            "status": health.status,
            "timestamp": now.isoformat()
        })

    async def get_all_health(self) -> list[AgentHealth]:
        """Get health status for all agents."""
        return list(self.agents.values())

    async def get_unhealthy_agents(self) -> list[AgentHealth]:
        """Get list of unhealthy agents."""
        return [h for h in self.agents.values() if h.status in ("unhealthy", "offline")]
```

### Automatic Recovery & Self-Healing

```python
# packages/core/src/ai_core/recovery.py
import asyncio
from datetime import datetime, timedelta
from typing import Optional
import subprocess

class AgentRecovery:
    """Automatic recovery system for failed agents."""

    def __init__(self, health_monitor, tmux_manager, redis_client):
        self.health = health_monitor
        self.tmux = tmux_manager
        self.redis = redis_client
        self.recovery_attempts: dict[str, int] = {}
        self.max_recovery_attempts = 3
        self.recovery_cooldown = timedelta(minutes=5)
        self.last_recovery: dict[str, datetime] = {}

    async def start_monitoring(self):
        """Start the recovery monitoring loop."""
        while True:
            try:
                await self._check_and_recover()
            except Exception as e:
                print(f"Recovery check error: {e}")
            await asyncio.sleep(10)

    async def _check_and_recover(self):
        """Check for unhealthy agents and attempt recovery."""
        unhealthy = await self.health.get_unhealthy_agents()

        for agent_health in unhealthy:
            agent_id = agent_health.agent_id

            # Check cooldown
            if agent_id in self.last_recovery:
                if datetime.utcnow() - self.last_recovery[agent_id] < self.recovery_cooldown:
                    continue

            # Check attempt limit
            attempts = self.recovery_attempts.get(agent_id, 0)
            if attempts >= self.max_recovery_attempts:
                await self._escalate_to_human(agent_id, agent_health)
                continue

            # Attempt recovery
            success = await self._recover_agent(agent_id, agent_health)

            self.recovery_attempts[agent_id] = attempts + 1
            self.last_recovery[agent_id] = datetime.utcnow()

            if success:
                self.recovery_attempts[agent_id] = 0

    async def _recover_agent(self, agent_id: str, health) -> bool:
        """Attempt to recover a failed agent."""
        print(f"Attempting recovery for {agent_id} (status: {health.status})")

        if health.status == "offline":
            # Agent not responding, restart it
            return await self._restart_agent(agent_id)

        elif health.status == "unhealthy":
            # High error rate, try soft restart first
            if health.error_rate_percent > 80:
                return await self._restart_agent(agent_id)
            else:
                # Try clearing task queue
                await self._clear_agent_queue(agent_id)
                return True

        return False

    async def _restart_agent(self, agent_id: str) -> bool:
        """Restart an agent in tmux."""
        try:
            # Kill existing window
            self.tmux.kill_window(agent_id)
            await asyncio.sleep(2)

            # Restart
            self.tmux.create_agent_window(agent_id)
            await asyncio.sleep(5)

            # Verify it's running
            health = await self.health.get_agent_health(agent_id)
            return health and health.status != "offline"

        except Exception as e:
            print(f"Failed to restart {agent_id}: {e}")
            return False

    async def _clear_agent_queue(self, agent_id: str):
        """Clear pending tasks for an agent."""
        await self.redis.delete(f"agent:{agent_id}:tasks")

    async def _reassign_tasks(self, agent_id: str):
        """Reassign pending tasks from failed agent."""
        pending_tasks = await self.redis.lrange(f"agent:{agent_id}:pending", 0, -1)

        for task_data in pending_tasks:
            # Re-publish to supervisor for reassignment
            await self.redis.publish("supervisor:reassign", {
                "original_agent": agent_id,
                "task": task_data
            })

    async def _escalate_to_human(self, agent_id: str, health):
        """Escalate to human when automatic recovery fails."""
        await self.redis.publish("alerts:critical", {
            "type": "agent_recovery_failed",
            "agent_id": agent_id,
            "status": health.status,
            "recovery_attempts": self.recovery_attempts.get(agent_id, 0),
            "message": f"Agent {agent_id} failed recovery after {self.max_recovery_attempts} attempts",
            "timestamp": datetime.utcnow().isoformat()
        })

        # Also send to supervisor for notification to user
        await self.redis.publish("supervisor:alert", {
            "severity": "critical",
            "message": f"Agent '{agent_id}' is down and automatic recovery failed. Manual intervention required.",
        })
```

### Agent SDK

```python
# packages/agent_sdk/src/ai_agent_sdk/__init__.py
from .agent import Agent, tool
from .types import Task, TaskResult, Message, Memory
from .communication import Channel, Broadcast

__all__ = ["Agent", "tool", "Task", "TaskResult", "Message", "Memory", "Channel", "Broadcast"]
```

```python
# packages/agent_sdk/src/ai_agent_sdk/agent.py
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from functools import wraps
from pathlib import Path
from typing import Callable, Optional, Any
import asyncio
import inspect

def tool(func: Callable = None, *, name: str = None, description: str = None, requires_approval: bool = False):
    """Decorator to mark a method as an agent tool."""
    def decorator(f):
        f._is_tool = True
        f._tool_name = name or f.__name__
        f._tool_description = description or f.__doc__ or ""
        f._requires_approval = requires_approval

        @wraps(f)
        async def wrapper(self, *args, **kwargs):
            # Pre-execution hooks
            if f._requires_approval:
                approved = await self._request_approval(f._tool_name, args, kwargs)
                if not approved:
                    raise PermissionError(f"Tool {f._tool_name} requires approval")

            # Execute
            result = await f(self, *args, **kwargs) if asyncio.iscoroutinefunction(f) else f(self, *args, **kwargs)

            # Post-execution logging
            await self._log_tool_execution(f._tool_name, args, kwargs, result)

            return result

        wrapper._is_tool = True
        wrapper._tool_name = f._tool_name
        wrapper._tool_description = f._tool_description
        wrapper._requires_approval = f._requires_approval
        return wrapper

    return decorator(func) if func else decorator

class Agent(ABC):
    """Base class for all agents. Subclass this to create new agents."""

    # Override these in subclasses
    name: str = "base_agent"
    description: str = "A base agent"
    version: str = "1.0.0"

    def __init__(self, config_path: Optional[Path] = None):
        self.config = self._load_config(config_path)
        self.tools = self._discover_tools()
        self.logger = self._setup_logger()
        self.metrics = self._setup_metrics()
        self.workspace = self._setup_workspace()
        self._running = False

    def _discover_tools(self) -> dict[str, Callable]:
        """Discover all tools defined on this agent."""
        tools = {}
        for name in dir(self):
            method = getattr(self, name)
            if callable(method) and getattr(method, '_is_tool', False):
                tools[method._tool_name] = method
        return tools

    @abstractmethod
    async def process_task(self, task) -> Any:
        """Process a task. Override this in subclasses."""
        pass

    async def run(self):
        """Main agent loop."""
        self._running = True
        self.logger.info(f"Starting agent: {self.name} v{self.version}")

        # Register with supervisor
        await self._register()

        # Start background tasks
        asyncio.create_task(self._heartbeat_loop())
        asyncio.create_task(self._hot_reload_loop())

        # Main task loop
        while self._running:
            try:
                task = await self._get_next_task()
                if task:
                    await self._execute_task(task)
            except Exception as e:
                self.logger.error(f"Error in main loop: {e}")
                await asyncio.sleep(1)

    async def _execute_task(self, task):
        """Execute a task with error handling and metrics."""
        start_time = asyncio.get_event_loop().time()
        try:
            result = await self.process_task(task)
            duration = asyncio.get_event_loop().time() - start_time
            self.metrics.record_task(task.type, duration, "success")
            await self._complete_task(task, result)
        except Exception as e:
            duration = asyncio.get_event_loop().time() - start_time
            self.metrics.record_task(task.type, duration, "failure")
            await self._fail_task(task, str(e))

    def get_tool_definitions(self) -> list[dict]:
        """Get tool definitions for Claude API."""
        definitions = []
        for name, method in self.tools.items():
            sig = inspect.signature(method)
            params = {}
            for param_name, param in sig.parameters.items():
                if param_name == 'self':
                    continue
                params[param_name] = {
                    "type": "string",  # Simplified, would inspect type hints
                    "description": ""
                }

            definitions.append({
                "name": name,
                "description": method._tool_description,
                "input_schema": {
                    "type": "object",
                    "properties": params,
                    "required": list(params.keys())
                }
            })
        return definitions

# Example agent using the SDK
class ExampleAgent(Agent):
    name = "example_agent"
    description = "An example agent demonstrating the SDK"

    @tool
    async def search_code(self, query: str, file_pattern: str = "*.py") -> str:
        """Search for code matching a query in files matching the pattern."""
        # Implementation
        return f"Found matches for '{query}' in {file_pattern}"

    @tool(requires_approval=True)
    async def delete_file(self, path: str) -> str:
        """Delete a file. Requires human approval."""
        # Implementation
        return f"Deleted {path}"

    async def process_task(self, task):
        # Use Claude to decide which tools to use
        pass
```

### Local Development Mode

```python
# scripts/dev.py
import asyncio
import argparse
from pathlib import Path

class LocalDevEnvironment:
    """Single-process development environment for debugging."""

    def __init__(self, mock_external: bool = True):
        self.mock_external = mock_external
        self.agents: dict[str, Agent] = {}
        self.message_queue: asyncio.Queue = asyncio.Queue()
        self.running = False

    async def start(self, agent_types: list[str] = None):
        """Start the dev environment."""
        self.running = True

        # Use in-memory Redis mock
        if self.mock_external:
            self.redis = InMemoryRedis()
            self.qdrant = InMemoryQdrant()
        else:
            # Connect to real services
            pass

        # Load agents
        agent_types = agent_types or ["supervisor", "code_agent"]
        for agent_type in agent_types:
            agent = self._load_agent(agent_type)
            self.agents[agent_type] = agent

        # Start message router
        asyncio.create_task(self._route_messages())

        # Start all agents
        for agent in self.agents.values():
            asyncio.create_task(agent.run())

        print(f"Development environment started with agents: {list(self.agents.keys())}")
        print("Press Ctrl+C to stop")

        # Keep running
        while self.running:
            await asyncio.sleep(1)

    async def send_message(self, content: str):
        """Send a message to the supervisor."""
        await self.message_queue.put({
            "type": "user_message",
            "content": content,
            "timestamp": asyncio.get_event_loop().time()
        })

class InMemoryRedis:
    """In-memory Redis mock for development."""

    def __init__(self):
        self.data: dict = {}
        self.pubsub_channels: dict[str, list] = {}
        self.streams: dict[str, list] = {}

    async def get(self, key: str):
        return self.data.get(key)

    async def set(self, key: str, value):
        self.data[key] = value

    async def publish(self, channel: str, message):
        if channel in self.pubsub_channels:
            for callback in self.pubsub_channels[channel]:
                await callback(message)

    async def subscribe(self, channel: str, callback):
        if channel not in self.pubsub_channels:
            self.pubsub_channels[channel] = []
        self.pubsub_channels[channel].append(callback)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--agents", nargs="+", default=["supervisor", "code_agent"])
    parser.add_argument("--mock", action="store_true", default=True)
    args = parser.parse_args()

    env = LocalDevEnvironment(mock_external=args.mock)
    asyncio.run(env.start(args.agents))
```

### Agent Testing Framework

```python
# packages/testing/src/ai_testing/harness.py
import asyncio
from dataclasses import dataclass
from typing import Optional, Any
from unittest.mock import MagicMock, AsyncMock

@dataclass
class AgentInvocation:
    agent_id: str
    tool_name: str
    arguments: dict
    result: Any
    timestamp: float

class AgentTestHarness:
    """Test harness for multi-agent integration testing."""

    def __init__(self):
        self.agents: dict[str, MagicMock] = {}
        self.invocations: list[AgentInvocation] = []
        self.messages: list[dict] = []
        self.mock_responses: dict[str, Any] = {}

    async def __aenter__(self):
        await self.setup()
        return self

    async def __aexit__(self, *args):
        await self.teardown()

    async def setup(self):
        """Set up test environment."""
        # Create mock agents
        for agent_type in ["supervisor", "code_agent", "data_agent", "qa_agent", "infra_agent", "research_agent"]:
            self.agents[agent_type] = self._create_mock_agent(agent_type)

    def _create_mock_agent(self, agent_type: str) -> MagicMock:
        agent = MagicMock()
        agent.agent_type = agent_type
        agent.invoked = False
        agent.invocation_count = 0

        async def process_task(task):
            agent.invoked = True
            agent.invocation_count += 1
            self.invocations.append(AgentInvocation(
                agent_id=agent_type,
                tool_name="process_task",
                arguments={"task": task},
                result=self.mock_responses.get(agent_type, {"status": "success"}),
                timestamp=asyncio.get_event_loop().time()
            ))
            return self.mock_responses.get(agent_type, {"status": "success"})

        agent.process_task = process_task
        return agent

    async def send_to_supervisor(self, message: str, files: list = None) -> str:
        """Send a message to the supervisor and get response."""
        self.messages.append({
            "role": "user",
            "content": message,
            "files": files
        })

        # Simulate supervisor processing
        supervisor = self.agents["supervisor"]
        result = await supervisor.process_task({
            "type": "user_request",
            "content": message
        })

        return result.get("response", "")

    def set_mock_response(self, agent_type: str, response: Any):
        """Set mock response for an agent."""
        self.mock_responses[agent_type] = response

    def was_invoked(self, agent_type: str) -> bool:
        """Check if an agent was invoked."""
        return self.agents[agent_type].invoked

    def get_invocations(self, agent_type: str = None) -> list[AgentInvocation]:
        """Get all invocations, optionally filtered by agent."""
        if agent_type:
            return [i for i in self.invocations if i.agent_id == agent_type]
        return self.invocations

    def assert_agent_invoked(self, agent_type: str, times: int = None):
        """Assert that an agent was invoked."""
        agent = self.agents[agent_type]
        assert agent.invoked, f"Agent {agent_type} was not invoked"
        if times is not None:
            assert agent.invocation_count == times, \
                f"Agent {agent_type} invoked {agent.invocation_count} times, expected {times}"

    def assert_tool_called(self, agent_type: str, tool_name: str):
        """Assert that a specific tool was called."""
        invocations = self.get_invocations(agent_type)
        tool_calls = [i for i in invocations if i.tool_name == tool_name]
        assert tool_calls, f"Tool {tool_name} was not called on {agent_type}"


# Example test
async def test_code_review_workflow():
    """Test that code review involves code and QA agents."""
    async with AgentTestHarness() as harness:
        # Set up expected responses
        harness.set_mock_response("code_agent", {
            "status": "success",
            "findings": ["Found unused import", "Missing docstring"]
        })
        harness.set_mock_response("qa_agent", {
            "status": "success",
            "security_issues": []
        })

        # Send request
        response = await harness.send_to_supervisor(
            "Review the authentication module for issues"
        )

        # Assertions
        harness.assert_agent_invoked("code_agent")
        harness.assert_agent_invoked("qa_agent")
        assert "findings" in response or "review" in response.lower()
```

### Graceful Degradation

```python
# packages/core/src/ai_core/resilience.py
import asyncio
from typing import TypeVar, Callable, Optional, Any
from functools import wraps
from datetime import datetime, timedelta

T = TypeVar('T')

class CircuitBreaker:
    """Circuit breaker for external service calls."""

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: timedelta = timedelta(seconds=30),
        half_open_requests: int = 3
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_requests = half_open_requests

        self.failures = 0
        self.last_failure: Optional[datetime] = None
        self.state = "closed"  # closed, open, half-open

    async def call(self, func: Callable[..., T], *args, **kwargs) -> T:
        if self.state == "open":
            if datetime.utcnow() - self.last_failure > self.recovery_timeout:
                self.state = "half-open"
            else:
                raise CircuitOpenError("Circuit breaker is open")

        try:
            result = await func(*args, **kwargs)
            if self.state == "half-open":
                self.state = "closed"
                self.failures = 0
            return result
        except Exception as e:
            self.failures += 1
            self.last_failure = datetime.utcnow()
            if self.failures >= self.failure_threshold:
                self.state = "open"
            raise

class CircuitOpenError(Exception):
    pass

class ResilientService:
    """Base class for services with fallback support."""

    def __init__(self):
        self.circuit_breakers: dict[str, CircuitBreaker] = {}

    def get_breaker(self, name: str) -> CircuitBreaker:
        if name not in self.circuit_breakers:
            self.circuit_breakers[name] = CircuitBreaker()
        return self.circuit_breakers[name]

class ResilientMemory(ResilientService):
    """Memory service with graceful degradation."""

    def __init__(self, qdrant_client, postgres_client, redis_client):
        super().__init__()
        self.qdrant = qdrant_client
        self.postgres = postgres_client
        self.redis = redis_client

    async def retrieve(self, query: str, limit: int = 5) -> list[dict]:
        """Retrieve memories with fallback chain."""

        # Try Qdrant first (primary)
        try:
            breaker = self.get_breaker("qdrant")
            return await breaker.call(self._qdrant_search, query, limit)
        except (CircuitOpenError, Exception) as e:
            print(f"Qdrant unavailable: {e}, falling back to PostgreSQL")

        # Fallback to PostgreSQL full-text search
        try:
            breaker = self.get_breaker("postgres")
            return await breaker.call(self._postgres_search, query, limit)
        except (CircuitOpenError, Exception) as e:
            print(f"PostgreSQL unavailable: {e}, falling back to Redis cache")

        # Last resort: Redis cache of recent queries
        try:
            cached = await self.redis.get(f"memory_cache:{query}")
            if cached:
                return cached
        except Exception:
            pass

        # Everything failed, return empty
        print("All memory backends unavailable, proceeding without context")
        return []

    async def _qdrant_search(self, query: str, limit: int) -> list[dict]:
        # Vector similarity search
        embedding = await self._get_embedding(query)
        results = await self.qdrant.search(
            collection_name="memories",
            query_vector=embedding,
            limit=limit
        )
        return [r.payload for r in results]

    async def _postgres_search(self, query: str, limit: int) -> list[dict]:
        # Full-text search fallback
        results = await self.postgres.fetch("""
            SELECT content, metadata
            FROM memories
            WHERE to_tsvector('english', content) @@ plainto_tsquery('english', $1)
            LIMIT $2
        """, query, limit)
        return [dict(r) for r in results]

def with_fallback(fallback_value: T):
    """Decorator that returns fallback value on any exception."""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                print(f"Function {func.__name__} failed: {e}, using fallback")
                return fallback_value
        return wrapper
    return decorator
```

### Horizontal Scaling Configuration

```yaml
# config/scaling.yaml
scaling:
  mode: single  # single | distributed

  single:
    max_agents: 10
    tmux_session: ai-infrastructure

  distributed:
    coordinator: redis
    coordinator_url: ${REDIS_URL}

    # Node configuration
    nodes:
      - id: node-1
        host: server1.example.com
        agents:
          - supervisor
          - code_agent
          - data_agent
      - id: node-2
        host: server2.example.com
        agents:
          - research_agent
          - qa_agent
      - id: node-3
        host: server3.example.com
        agents:
          - infra_agent

    # Agent affinity rules
    affinity:
      infra_agent:
        # Must run on node with Docker socket access
        required_capabilities:
          - docker
          - systemd
        node_selector:
          - node-1
          - node-3

      data_agent:
        # Prefer nodes close to database
        preferred_capabilities:
          - low_db_latency

    # Load balancing
    load_balancing:
      strategy: round_robin  # round_robin | least_loaded | random
      health_check_interval: 10s

    # Failover
    failover:
      enabled: true
      detection_timeout: 30s
      recovery_delay: 5s

    # Resource limits per node
    resources:
      max_memory_mb: 8192
      max_cpu_percent: 80
      max_agents_per_node: 5
```

### Conversation Checkpointing

```python
# packages/core/src/ai_core/checkpoint.py
import json
import asyncio
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Optional, Any
import gzip

@dataclass
class ConversationState:
    conversation_id: str
    user_id: str
    messages: list[dict]
    agent_states: dict[str, dict]
    pending_tasks: list[dict]
    working_memory: dict
    created_at: datetime
    checkpoint_at: datetime
    version: int = 1

class CheckpointManager:
    """Manages conversation checkpoints for recovery."""

    def __init__(self, storage_path: Path, redis_client, s3_client=None):
        self.storage_path = storage_path
        self.redis = redis_client
        self.s3 = s3_client
        self.storage_path.mkdir(parents=True, exist_ok=True)

    async def save_checkpoint(self, state: ConversationState):
        """Save a conversation checkpoint."""
        checkpoint_data = asdict(state)
        checkpoint_data["created_at"] = state.created_at.isoformat()
        checkpoint_data["checkpoint_at"] = state.checkpoint_at.isoformat()

        # Save to Redis for fast recovery
        await self.redis.set(
            f"checkpoint:{state.conversation_id}",
            json.dumps(checkpoint_data),
            ex=86400 * 7  # 7 days TTL
        )

        # Save to local disk (compressed)
        local_path = self.storage_path / f"{state.conversation_id}_{state.version}.json.gz"
        with gzip.open(local_path, 'wt') as f:
            json.dump(checkpoint_data, f)

        # Save to S3 for long-term storage
        if self.s3:
            await self._save_to_s3(state.conversation_id, checkpoint_data)

    async def load_checkpoint(self, conversation_id: str) -> Optional[ConversationState]:
        """Load a conversation checkpoint."""
        # Try Redis first
        data = await self.redis.get(f"checkpoint:{conversation_id}")
        if data:
            return self._deserialize(json.loads(data))

        # Try local disk
        checkpoints = sorted(
            self.storage_path.glob(f"{conversation_id}_*.json.gz"),
            reverse=True
        )
        if checkpoints:
            with gzip.open(checkpoints[0], 'rt') as f:
                return self._deserialize(json.load(f))

        # Try S3
        if self.s3:
            data = await self._load_from_s3(conversation_id)
            if data:
                return self._deserialize(data)

        return None

    async def restore_conversation(self, conversation_id: str, agents: dict):
        """Restore a conversation from checkpoint."""
        state = await self.load_checkpoint(conversation_id)
        if not state:
            raise ValueError(f"No checkpoint found for {conversation_id}")

        # Restore agent states
        for agent_id, agent_state in state.agent_states.items():
            if agent_id in agents:
                await agents[agent_id].restore_state(agent_state)

        # Re-queue pending tasks
        for task in state.pending_tasks:
            await self.redis.lpush("tasks:pending", json.dumps(task))

        return state

    def _deserialize(self, data: dict) -> ConversationState:
        data["created_at"] = datetime.fromisoformat(data["created_at"])
        data["checkpoint_at"] = datetime.fromisoformat(data["checkpoint_at"])
        return ConversationState(**data)

    async def auto_checkpoint(self, conversation_id: str, interval_seconds: int = 60):
        """Automatically checkpoint at regular intervals."""
        while True:
            await asyncio.sleep(interval_seconds)
            state = await self._gather_state(conversation_id)
            if state:
                await self.save_checkpoint(state)
```

### Multi-User Support

```python
# packages/core/src/ai_core/multiuser.py
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
from pathlib import Path

@dataclass
class UserSession:
    user_id: str
    session_id: str
    conversation_id: str
    workspace: Path
    memory_namespace: str
    created_at: datetime
    last_active: datetime
    rate_limits: 'RateLimits'
    permissions: list[str]

@dataclass
class RateLimits:
    requests_per_minute: int = 60
    tokens_per_hour: int = 100000
    concurrent_tasks: int = 5
    max_file_size_mb: int = 50

class UserManager:
    """Manages multi-user sessions with isolation."""

    def __init__(self, base_workspace: Path, redis_client):
        self.base_workspace = base_workspace
        self.redis = redis_client
        self.sessions: dict[str, UserSession] = {}

    async def create_session(self, user_id: str) -> UserSession:
        """Create a new isolated session for a user."""
        session_id = f"{user_id}_{datetime.utcnow().timestamp()}"

        # Create isolated workspace
        workspace = self.base_workspace / "users" / user_id / session_id
        workspace.mkdir(parents=True, exist_ok=True)

        # Create session
        session = UserSession(
            user_id=user_id,
            session_id=session_id,
            conversation_id=session_id,
            workspace=workspace,
            memory_namespace=f"user:{user_id}",
            created_at=datetime.utcnow(),
            last_active=datetime.utcnow(),
            rate_limits=await self._get_user_limits(user_id),
            permissions=await self._get_user_permissions(user_id)
        )

        self.sessions[session_id] = session
        await self._persist_session(session)

        return session

    async def get_session(self, session_id: str) -> Optional[UserSession]:
        """Get an existing session."""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            session.last_active = datetime.utcnow()
            return session

        # Try to load from Redis
        data = await self.redis.hgetall(f"session:{session_id}")
        if data:
            return self._deserialize_session(data)

        return None

    async def check_rate_limit(self, session: UserSession, tokens: int = 0) -> bool:
        """Check if user is within rate limits."""
        limits = session.rate_limits

        # Check requests per minute
        key = f"rate:{session.user_id}:rpm"
        current = await self.redis.incr(key)
        if current == 1:
            await self.redis.expire(key, 60)
        if current > limits.requests_per_minute:
            return False

        # Check tokens per hour
        if tokens > 0:
            key = f"rate:{session.user_id}:tph"
            current = await self.redis.incrby(key, tokens)
            if await self.redis.ttl(key) < 0:
                await self.redis.expire(key, 3600)
            if current > limits.tokens_per_hour:
                return False

        return True

    def get_user_memory_filter(self, session: UserSession) -> dict:
        """Get Qdrant filter for user's memory namespace."""
        return {
            "must": [
                {"key": "namespace", "match": {"value": session.memory_namespace}}
            ]
        }
```

### Plugin System

```yaml
# plugins/slack_integration/manifest.yaml
name: slack_integration
version: 1.0.0
description: Slack integration for notifications and commands
author: AI Infrastructure Team

requires:
  - ai_core >= 1.0.0

permissions:
  - network:slack.com
  - send_notifications

config:
  slack_webhook_url:
    type: string
    required: true
    secret: true
  slack_channel:
    type: string
    default: "#ai-infrastructure"

tools:
  - name: send_slack_message
    description: Send a message to Slack
    handler: tools:send_message
  - name: create_slack_thread
    description: Create a Slack thread for a conversation
    handler: tools:create_thread

hooks:
  - event: task_completed
    handler: hooks:on_task_completed
  - event: agent_error
    handler: hooks:on_agent_error
```

```python
# packages/core/src/ai_core/plugins.py
import importlib.util
from pathlib import Path
from dataclasses import dataclass
from typing import Callable, Any
import yaml

@dataclass
class Plugin:
    name: str
    version: str
    description: str
    tools: dict[str, Callable]
    hooks: dict[str, Callable]
    config: dict

class PluginManager:
    """Dynamic plugin loading and management."""

    def __init__(self, plugins_dir: Path):
        self.plugins_dir = plugins_dir
        self.plugins: dict[str, Plugin] = {}
        self.hooks: dict[str, list[Callable]] = {}

    def discover_plugins(self) -> list[str]:
        """Discover available plugins."""
        plugins = []
        for path in self.plugins_dir.iterdir():
            if path.is_dir() and (path / "manifest.yaml").exists():
                plugins.append(path.name)
        return plugins

    def load_plugin(self, name: str, config: dict = None) -> Plugin:
        """Load a plugin by name."""
        plugin_path = self.plugins_dir / name
        manifest_path = plugin_path / "manifest.yaml"

        with open(manifest_path) as f:
            manifest = yaml.safe_load(f)

        # Load tools
        tools = {}
        for tool_def in manifest.get("tools", []):
            module_name, func_name = tool_def["handler"].split(":")
            module = self._load_module(plugin_path / f"{module_name}.py")
            tools[tool_def["name"]] = getattr(module, func_name)

        # Load hooks
        hooks = {}
        for hook_def in manifest.get("hooks", []):
            module_name, func_name = hook_def["handler"].split(":")
            module = self._load_module(plugin_path / f"{module_name}.py")
            event = hook_def["event"]
            hooks[event] = getattr(module, func_name)

            # Register with global hook registry
            if event not in self.hooks:
                self.hooks[event] = []
            self.hooks[event].append(hooks[event])

        plugin = Plugin(
            name=manifest["name"],
            version=manifest["version"],
            description=manifest["description"],
            tools=tools,
            hooks=hooks,
            config=config or {}
        )

        self.plugins[name] = plugin
        return plugin

    def _load_module(self, path: Path):
        """Dynamically load a Python module."""
        spec = importlib.util.spec_from_file_location(path.stem, path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return module

    async def trigger_hook(self, event: str, data: Any):
        """Trigger all hooks for an event."""
        for handler in self.hooks.get(event, []):
            try:
                await handler(data)
            except Exception as e:
                print(f"Hook error for {event}: {e}")

    def get_all_tools(self) -> dict[str, Callable]:
        """Get all tools from all loaded plugins."""
        all_tools = {}
        for plugin in self.plugins.values():
            all_tools.update(plugin.tools)
        return all_tools
```

### Scheduled Tasks / Cron Agent

```yaml
# config/scheduled_tasks.yaml
scheduled_tasks:
  # Security scanning
  - name: daily_security_scan
    cron: "0 3 * * *"              # 3 AM daily
    agent: qa_agent
    prompt: |
      Run a comprehensive security scan on the codebase:
      1. Check for outdated dependencies with known vulnerabilities
      2. Scan for hardcoded secrets or credentials
      3. Review recent code changes for security issues
      4. Check Docker images for vulnerabilities
      Report findings in a structured format.
    timeout_minutes: 30
    notify_on_failure: true

  # Dependency updates
  - name: weekly_dependency_check
    cron: "0 4 * * 0"              # 4 AM Sunday
    agent: code_agent
    prompt: |
      Check for outdated dependencies across all packages:
      1. List all outdated packages with current and latest versions
      2. Check changelogs for breaking changes
      3. If safe updates available, create a PR with updates
    requires_approval: true        # Human must approve PRs
    timeout_minutes: 60

  # Backup verification
  - name: daily_backup_verify
    cron: "0 5 * * *"              # 5 AM daily
    agent: infra_agent
    prompt: |
      Verify that all backups completed successfully:
      1. Check PostgreSQL backup status
      2. Verify Redis RDB snapshot
      3. Confirm GitHub backup sync
      4. Test restore procedure on a sample
    notify_on_failure: true

  # Memory optimization
  - name: weekly_memory_cleanup
    cron: "0 2 * * 6"              # 2 AM Saturday
    agent: data_agent
    prompt: |
      Optimize the memory/knowledge system:
      1. Remove duplicate embeddings
      2. Archive old, unused memories
      3. Compact the vector index
      4. Report on memory usage statistics

  # Health report
  - name: daily_health_report
    cron: "0 8 * * *"              # 8 AM daily
    agent: supervisor
    prompt: |
      Generate a daily health report:
      1. Summarize agent activity over the past 24 hours
      2. List any errors or issues encountered
      3. Report on resource usage
      4. Highlight any concerning trends
    output: report                 # Save as report instead of just logging

  # SSL certificate check
  - name: weekly_ssl_check
    cron: "0 6 * * 1"              # 6 AM Monday
    agent: infra_agent
    prompt: |
      Check SSL certificates for all domains:
      1. List all managed domains
      2. Check certificate expiration dates
      3. Renew any certificates expiring within 14 days
      4. Report on certificate status
    notify_on_failure: true
```

```python
# packages/core/src/ai_core/scheduler.py
import asyncio
from croniter import croniter
from datetime import datetime
from dataclasses import dataclass
from typing import Optional
import yaml

@dataclass
class ScheduledTask:
    name: str
    cron: str
    agent: str
    prompt: str
    timeout_minutes: int = 30
    requires_approval: bool = False
    notify_on_failure: bool = False
    output: str = "log"  # log | report | none
    enabled: bool = True

class TaskScheduler:
    """Cron-like scheduler for autonomous tasks."""

    def __init__(self, config_path: str, supervisor_client):
        with open(config_path) as f:
            config = yaml.safe_load(f)

        self.tasks = [
            ScheduledTask(**task)
            for task in config.get("scheduled_tasks", [])
        ]
        self.supervisor = supervisor_client
        self.running = False

    async def start(self):
        """Start the scheduler."""
        self.running = True
        print(f"Scheduler started with {len(self.tasks)} tasks")

        while self.running:
            now = datetime.utcnow()

            for task in self.tasks:
                if not task.enabled:
                    continue

                if self._should_run(task, now):
                    asyncio.create_task(self._execute_task(task))

            # Check every minute
            await asyncio.sleep(60)

    def _should_run(self, task: ScheduledTask, now: datetime) -> bool:
        """Check if task should run at current time."""
        cron = croniter(task.cron, now)
        prev_run = cron.get_prev(datetime)
        # Run if within the last minute
        return (now - prev_run).total_seconds() < 60

    async def _execute_task(self, task: ScheduledTask):
        """Execute a scheduled task."""
        print(f"Executing scheduled task: {task.name}")

        try:
            if task.requires_approval:
                # Queue for human approval
                await self._queue_for_approval(task)
            else:
                # Execute directly
                result = await self.supervisor.execute_task(
                    agent=task.agent,
                    prompt=task.prompt,
                    timeout=task.timeout_minutes * 60
                )

                if task.output == "report":
                    await self._save_report(task.name, result)

        except asyncio.TimeoutError:
            print(f"Task {task.name} timed out")
            if task.notify_on_failure:
                await self._notify_failure(task, "Timeout")
        except Exception as e:
            print(f"Task {task.name} failed: {e}")
            if task.notify_on_failure:
                await self._notify_failure(task, str(e))

    async def _queue_for_approval(self, task: ScheduledTask):
        """Queue task for human approval before execution."""
        await self.supervisor.send_message(
            f"Scheduled task '{task.name}' requires approval.\n\n"
            f"**Task:** {task.prompt[:200]}...\n\n"
            f"Reply 'approve {task.name}' to execute or 'skip {task.name}' to cancel."
        )
```

### Knowledge Ingestion Pipeline

```python
# packages/memory/src/ai_memory/ingestion.py
import asyncio
from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import AsyncIterator, Optional
import hashlib

@dataclass
class Document:
    id: str
    content: str
    source: str
    source_type: str
    metadata: dict
    created_at: datetime
    content_hash: str

class KnowledgeSource(ABC):
    """Base class for knowledge sources."""

    @abstractmethod
    async def fetch(self) -> AsyncIterator[Document]:
        """Fetch documents from the source."""
        pass

    @abstractmethod
    async def watch(self) -> AsyncIterator[Document]:
        """Watch for changes and yield new/updated documents."""
        pass

class GitRepoSource(KnowledgeSource):
    """Ingest knowledge from a git repository."""

    def __init__(self, repo_path: Path, branch: str = "main", patterns: list[str] = None):
        self.repo_path = repo_path
        self.branch = branch
        self.patterns = patterns or ["*.md", "*.py", "*.ts", "*.js"]
        self.processed_hashes: set[str] = set()

    async def fetch(self) -> AsyncIterator[Document]:
        """Fetch all matching files from the repository."""
        for pattern in self.patterns:
            for file_path in self.repo_path.rglob(pattern):
                if ".git" in str(file_path):
                    continue

                content = file_path.read_text()
                content_hash = hashlib.md5(content.encode()).hexdigest()

                yield Document(
                    id=f"git:{self.repo_path.name}:{file_path.relative_to(self.repo_path)}",
                    content=content,
                    source=str(file_path),
                    source_type="git_repo",
                    metadata={
                        "repo": self.repo_path.name,
                        "branch": self.branch,
                        "file_type": file_path.suffix,
                        "relative_path": str(file_path.relative_to(self.repo_path))
                    },
                    created_at=datetime.utcnow(),
                    content_hash=content_hash
                )

                self.processed_hashes.add(content_hash)

    async def watch(self) -> AsyncIterator[Document]:
        """Watch for file changes using polling."""
        while True:
            async for doc in self.fetch():
                if doc.content_hash not in self.processed_hashes:
                    self.processed_hashes.add(doc.content_hash)
                    yield doc
            await asyncio.sleep(60)  # Poll every minute

class WebSource(KnowledgeSource):
    """Ingest knowledge from web URLs."""

    def __init__(self, urls: list[str], refresh_hours: int = 24):
        self.urls = urls
        self.refresh_hours = refresh_hours
        self.last_fetch: dict[str, datetime] = {}

    async def fetch(self) -> AsyncIterator[Document]:
        import httpx
        from bs4 import BeautifulSoup

        async with httpx.AsyncClient() as client:
            for url in self.urls:
                try:
                    response = await client.get(url)
                    soup = BeautifulSoup(response.text, 'html.parser')

                    # Extract main content
                    content = soup.get_text(separator='\n', strip=True)
                    content_hash = hashlib.md5(content.encode()).hexdigest()

                    yield Document(
                        id=f"web:{url}",
                        content=content,
                        source=url,
                        source_type="web",
                        metadata={
                            "url": url,
                            "title": soup.title.string if soup.title else "",
                        },
                        created_at=datetime.utcnow(),
                        content_hash=content_hash
                    )

                    self.last_fetch[url] = datetime.utcnow()
                except Exception as e:
                    print(f"Failed to fetch {url}: {e}")

class KnowledgeIngestionPipeline:
    """Pipeline for ingesting and indexing knowledge."""

    def __init__(self, sources: list[KnowledgeSource], qdrant_client, embedding_service):
        self.sources = sources
        self.qdrant = qdrant_client
        self.embeddings = embedding_service
        self.chunk_size = 1000
        self.chunk_overlap = 200

    async def run_full_ingestion(self):
        """Run full ingestion from all sources."""
        for source in self.sources:
            async for document in source.fetch():
                await self._process_document(document)

    async def start_continuous_ingestion(self):
        """Start continuous ingestion watching for changes."""
        tasks = [
            asyncio.create_task(self._watch_source(source))
            for source in self.sources
        ]
        await asyncio.gather(*tasks)

    async def _watch_source(self, source: KnowledgeSource):
        """Watch a single source for changes."""
        async for document in source.watch():
            await self._process_document(document)

    async def _process_document(self, document: Document):
        """Process and index a document."""
        # Chunk the document
        chunks = self._chunk_text(document.content)

        # Generate embeddings
        embeddings = await self.embeddings.embed_batch([c for c in chunks])

        # Store in Qdrant
        points = [
            {
                "id": f"{document.id}:chunk:{i}",
                "vector": embedding,
                "payload": {
                    "content": chunk,
                    "document_id": document.id,
                    "source": document.source,
                    "source_type": document.source_type,
                    "chunk_index": i,
                    **document.metadata
                }
            }
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings))
        ]

        await self.qdrant.upsert(collection_name="knowledge", points=points)
        print(f"Indexed {len(chunks)} chunks from {document.source}")

    def _chunk_text(self, text: str) -> list[str]:
        """Split text into overlapping chunks."""
        chunks = []
        start = 0
        while start < len(text):
            end = start + self.chunk_size
            chunk = text[start:end]
            chunks.append(chunk)
            start = end - self.chunk_overlap
        return chunks
```

### Agent Memory Sharing Protocol

```python
# packages/messaging/src/ai_messaging/knowledge_share.py
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Optional
from uuid import UUID, uuid4

class KnowledgeType(Enum):
    PATTERN = "pattern"           # Code pattern, best practice
    PROCEDURE = "procedure"       # How to do something
    FACT = "fact"                # Factual information
    WARNING = "warning"          # Something to avoid
    INSIGHT = "insight"          # Learned insight
    TOOL_USAGE = "tool_usage"    # How to use a tool effectively

@dataclass
class KnowledgeShare:
    """Structured knowledge sharing between agents."""

    id: UUID = field(default_factory=uuid4)
    source_agent: str = ""
    knowledge_type: KnowledgeType = KnowledgeType.FACT
    title: str = ""
    content: str = ""
    confidence: float = 0.8      # 0-1, how confident the agent is
    evidence: list[str] = field(default_factory=list)  # References
    context: dict = field(default_factory=dict)        # When this applies
    expiry: Optional[datetime] = None                   # When knowledge becomes stale
    created_at: datetime = field(default_factory=datetime.utcnow)

    # Feedback tracking
    upvotes: int = 0
    downvotes: int = 0
    usage_count: int = 0

class KnowledgeShareProtocol:
    """Protocol for agents to share and consume knowledge."""

    def __init__(self, redis_client, qdrant_client, embedding_service):
        self.redis = redis_client
        self.qdrant = qdrant_client
        self.embeddings = embedding_service
        self.channel = "knowledge:shared"

    async def share(self, knowledge: KnowledgeShare):
        """Share knowledge with all agents."""
        # Generate embedding for the knowledge
        text = f"{knowledge.title}\n{knowledge.content}"
        embedding = await self.embeddings.embed(text)

        # Store in vector DB
        await self.qdrant.upsert(
            collection_name="shared_knowledge",
            points=[{
                "id": str(knowledge.id),
                "vector": embedding,
                "payload": {
                    "source_agent": knowledge.source_agent,
                    "knowledge_type": knowledge.knowledge_type.value,
                    "title": knowledge.title,
                    "content": knowledge.content,
                    "confidence": knowledge.confidence,
                    "evidence": knowledge.evidence,
                    "context": knowledge.context,
                    "expiry": knowledge.expiry.isoformat() if knowledge.expiry else None,
                    "created_at": knowledge.created_at.isoformat(),
                }
            }]
        )

        # Broadcast to all agents
        await self.redis.publish(self.channel, {
            "type": "new_knowledge",
            "knowledge_id": str(knowledge.id),
            "source_agent": knowledge.source_agent,
            "title": knowledge.title,
            "knowledge_type": knowledge.knowledge_type.value
        })

    async def query(
        self,
        query: str,
        knowledge_types: list[KnowledgeType] = None,
        min_confidence: float = 0.5,
        limit: int = 5
    ) -> list[KnowledgeShare]:
        """Query for relevant shared knowledge."""
        embedding = await self.embeddings.embed(query)

        filters = {"must": []}
        if knowledge_types:
            filters["must"].append({
                "key": "knowledge_type",
                "match": {"any": [kt.value for kt in knowledge_types]}
            })
        filters["must"].append({
            "key": "confidence",
            "range": {"gte": min_confidence}
        })

        results = await self.qdrant.search(
            collection_name="shared_knowledge",
            query_vector=embedding,
            query_filter=filters,
            limit=limit
        )

        return [
            KnowledgeShare(
                id=UUID(r.id),
                **r.payload
            )
            for r in results
        ]

    async def feedback(self, knowledge_id: UUID, helpful: bool, agent_id: str):
        """Provide feedback on shared knowledge."""
        key = f"knowledge:{knowledge_id}:feedback"
        if helpful:
            await self.redis.hincrby(key, "upvotes", 1)
        else:
            await self.redis.hincrby(key, "downvotes", 1)

        await self.redis.hincrby(key, "usage_count", 1)
        await self.redis.lpush(f"{key}:agents", agent_id)

    async def subscribe(self, callback):
        """Subscribe to new knowledge broadcasts."""
        pubsub = self.redis.pubsub()
        await pubsub.subscribe(self.channel)

        async for message in pubsub.listen():
            if message["type"] == "message":
                await callback(message["data"])
```

### Self-Management (Size & Memory)

The system autonomously manages its own resource usage, cleaning up old data and optimizing storage.

```python
# packages/core/src/ai_core/self_management.py
import asyncio
import psutil
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

@dataclass
class ResourceThresholds:
    max_memory_percent: float = 80.0
    max_disk_percent: float = 85.0
    max_qdrant_vectors: int = 10_000_000
    max_postgres_rows: int = 50_000_000
    max_log_age_days: int = 30
    max_checkpoint_age_days: int = 7
    max_temp_file_age_hours: int = 24

class SelfManager:
    """Autonomous resource and memory management."""

    def __init__(self, config: ResourceThresholds, redis_client, qdrant_client, postgres_client):
        self.config = config
        self.redis = redis_client
        self.qdrant = qdrant_client
        self.postgres = postgres_client
        self.last_cleanup: Optional[datetime] = None

    async def start_monitoring(self, check_interval: int = 300):
        """Start continuous resource monitoring."""
        while True:
            try:
                status = await self.check_resources()
                if status.needs_cleanup:
                    await self.perform_cleanup(status)
            except Exception as e:
                print(f"Self-management error: {e}")
            await asyncio.sleep(check_interval)

    async def check_resources(self) -> 'ResourceStatus':
        """Check all resource levels."""
        return ResourceStatus(
            memory_percent=psutil.virtual_memory().percent,
            disk_percent=psutil.disk_usage('/').percent,
            qdrant_count=await self._get_qdrant_count(),
            postgres_rows=await self._get_postgres_rows(),
            redis_memory_mb=await self._get_redis_memory(),
            temp_files_size_mb=self._get_temp_size(),
            log_files_size_mb=self._get_log_size(),
        )

    async def perform_cleanup(self, status: 'ResourceStatus'):
        """Perform cleanup based on resource status."""
        print(f"Starting cleanup - Memory: {status.memory_percent}%, Disk: {status.disk_percent}%")

        tasks = []

        # Clean old logs
        if status.log_files_size_mb > 500:
            tasks.append(self._cleanup_logs())

        # Clean temp files
        if status.temp_files_size_mb > 1000:
            tasks.append(self._cleanup_temp_files())

        # Clean old checkpoints
        tasks.append(self._cleanup_old_checkpoints())

        # Compact Qdrant if too many vectors
        if status.qdrant_count > self.config.max_qdrant_vectors * 0.9:
            tasks.append(self._compact_qdrant())

        # Archive old PostgreSQL data
        if status.postgres_rows > self.config.max_postgres_rows * 0.9:
            tasks.append(self._archive_old_data())

        # Clean Redis cache
        if status.redis_memory_mb > 1000:
            tasks.append(self._cleanup_redis_cache())

        await asyncio.gather(*tasks)
        self.last_cleanup = datetime.utcnow()

        # Report cleanup results
        await self._report_cleanup()

    async def _cleanup_logs(self):
        """Remove old log files."""
        log_dir = Path("/var/log/ai-infrastructure")
        cutoff = datetime.utcnow() - timedelta(days=self.config.max_log_age_days)

        for log_file in log_dir.glob("*.log*"):
            if datetime.fromtimestamp(log_file.stat().st_mtime) < cutoff:
                log_file.unlink()
                print(f"Removed old log: {log_file}")

    async def _compact_qdrant(self):
        """Optimize Qdrant collections."""
        collections = ["memories", "knowledge", "shared_knowledge"]
        for collection in collections:
            # Remove old, low-usage entries
            await self.qdrant.delete(
                collection_name=collection,
                points_selector={
                    "filter": {
                        "must": [
                            {"key": "created_at", "range": {"lt": (datetime.utcnow() - timedelta(days=90)).isoformat()}},
                            {"key": "usage_count", "range": {"lt": 5}}
                        ]
                    }
                }
            )
        print("Qdrant compaction complete")

    async def _archive_old_data(self):
        """Archive old PostgreSQL data to cold storage."""
        # Move old conversations to archive table
        await self.postgres.execute("""
            INSERT INTO conversations_archive
            SELECT * FROM conversations
            WHERE created_at < NOW() - INTERVAL '90 days'
            AND NOT pinned;

            DELETE FROM conversations
            WHERE created_at < NOW() - INTERVAL '90 days'
            AND NOT pinned;
        """)

        # Vacuum to reclaim space
        await self.postgres.execute("VACUUM ANALYZE;")
        print("PostgreSQL archival complete")

    async def get_resource_report(self) -> dict:
        """Generate a resource usage report."""
        status = await self.check_resources()
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "memory": {
                "percent": status.memory_percent,
                "status": "ok" if status.memory_percent < 70 else "warning" if status.memory_percent < 85 else "critical"
            },
            "disk": {
                "percent": status.disk_percent,
                "status": "ok" if status.disk_percent < 70 else "warning" if status.disk_percent < 85 else "critical"
            },
            "qdrant_vectors": status.qdrant_count,
            "postgres_rows": status.postgres_rows,
            "redis_memory_mb": status.redis_memory_mb,
            "last_cleanup": self.last_cleanup.isoformat() if self.last_cleanup else None,
            "recommendations": self._generate_recommendations(status)
        }

@dataclass
class ResourceStatus:
    memory_percent: float
    disk_percent: float
    qdrant_count: int
    postgres_rows: int
    redis_memory_mb: float
    temp_files_size_mb: float
    log_files_size_mb: float

    @property
    def needs_cleanup(self) -> bool:
        return (
            self.memory_percent > 75 or
            self.disk_percent > 80 or
            self.temp_files_size_mb > 500 or
            self.log_files_size_mb > 1000
        )
```

### Proactive Bug Detection & Self-Improvement

Agents continuously analyze their own performance and suggest improvements.

```python
# packages/core/src/ai_core/self_improvement.py
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Optional
from uuid import UUID, uuid4

class ImprovementType(Enum):
    BUG_FIX = "bug_fix"
    PERFORMANCE = "performance"
    SECURITY = "security"
    CODE_QUALITY = "code_quality"
    FEATURE = "feature"
    DOCUMENTATION = "documentation"
    REFACTOR = "refactor"

class Priority(Enum):
    CRITICAL = 1
    HIGH = 2
    MEDIUM = 3
    LOW = 4

@dataclass
class ImprovementSuggestion:
    id: UUID = field(default_factory=uuid4)
    type: ImprovementType = ImprovementType.BUG_FIX
    priority: Priority = Priority.MEDIUM
    title: str = ""
    description: str = ""
    affected_files: list[str] = field(default_factory=list)
    suggested_fix: Optional[str] = None
    detected_by: str = ""              # Agent that detected it
    confidence: float = 0.8
    evidence: list[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.utcnow)
    status: str = "pending"            # pending, approved, rejected, implemented
    votes: dict[str, int] = field(default_factory=dict)  # agent_id -> vote (-1, 0, 1)

class ProactiveAnalyzer:
    """Proactively detects bugs and suggests improvements."""

    def __init__(self, redis_client, qdrant_client):
        self.redis = redis_client
        self.qdrant = qdrant_client
        self.suggestions: dict[UUID, ImprovementSuggestion] = {}

    async def start_analysis_loop(self, interval_hours: int = 6):
        """Run periodic proactive analysis."""
        while True:
            await self._run_analysis()
            await asyncio.sleep(interval_hours * 3600)

    async def _run_analysis(self):
        """Run all analysis types."""
        analyses = [
            self._analyze_error_patterns(),
            self._analyze_performance_bottlenecks(),
            self._analyze_code_quality(),
            self._analyze_security_issues(),
            self._analyze_test_coverage(),
            self._analyze_documentation_gaps(),
        ]
        await asyncio.gather(*analyses)

    async def _analyze_error_patterns(self):
        """Detect recurring errors and suggest fixes."""
        # Query error logs from last 7 days
        errors = await self.redis.lrange("errors:recent", 0, 1000)

        # Group by error type
        error_counts = {}
        for error in errors:
            key = f"{error.get('type')}:{error.get('message')[:100]}"
            if key not in error_counts:
                error_counts[key] = {"count": 0, "examples": []}
            error_counts[key]["count"] += 1
            if len(error_counts[key]["examples"]) < 3:
                error_counts[key]["examples"].append(error)

        # Suggest fixes for recurring errors
        for key, data in error_counts.items():
            if data["count"] >= 5:
                suggestion = ImprovementSuggestion(
                    type=ImprovementType.BUG_FIX,
                    priority=Priority.HIGH if data["count"] > 20 else Priority.MEDIUM,
                    title=f"Recurring error: {key[:50]}",
                    description=f"This error has occurred {data['count']} times in the last 7 days.",
                    evidence=[str(e) for e in data["examples"]],
                    detected_by="proactive_analyzer",
                    confidence=min(0.5 + (data["count"] / 100), 0.95)
                )
                await self.submit_suggestion(suggestion)

    async def _analyze_performance_bottlenecks(self):
        """Detect slow operations and suggest optimizations."""
        # Query performance metrics
        slow_operations = await self.redis.zrevrange("metrics:slow_operations", 0, 20, withscores=True)

        for operation, avg_time in slow_operations:
            if avg_time > 5000:  # > 5 seconds
                suggestion = ImprovementSuggestion(
                    type=ImprovementType.PERFORMANCE,
                    priority=Priority.MEDIUM,
                    title=f"Slow operation: {operation}",
                    description=f"Average execution time: {avg_time:.0f}ms. Consider optimization.",
                    detected_by="proactive_analyzer",
                    confidence=0.8
                )
                await self.submit_suggestion(suggestion)

    async def _analyze_security_issues(self):
        """Detect potential security issues."""
        issues = []

        # Check for outdated dependencies
        # Check for exposed secrets in logs
        # Check for permission escalations
        # Check for unusual network traffic

        for issue in issues:
            suggestion = ImprovementSuggestion(
                type=ImprovementType.SECURITY,
                priority=Priority.CRITICAL,
                title=issue["title"],
                description=issue["description"],
                detected_by="proactive_analyzer",
                confidence=issue.get("confidence", 0.9)
            )
            await self.submit_suggestion(suggestion)

    async def submit_suggestion(self, suggestion: ImprovementSuggestion):
        """Submit a new improvement suggestion."""
        self.suggestions[suggestion.id] = suggestion

        # Store in Redis
        await self.redis.hset(
            f"suggestions:{suggestion.id}",
            mapping={
                "type": suggestion.type.value,
                "priority": suggestion.priority.value,
                "title": suggestion.title,
                "description": suggestion.description,
                "status": suggestion.status,
                "created_at": suggestion.created_at.isoformat()
            }
        )

        # Notify supervisor
        await self.redis.publish("suggestions:new", {
            "id": str(suggestion.id),
            "type": suggestion.type.value,
            "priority": suggestion.priority.value,
            "title": suggestion.title
        })

    async def get_pending_suggestions(self, limit: int = 20) -> list[ImprovementSuggestion]:
        """Get pending suggestions sorted by priority."""
        pending = [s for s in self.suggestions.values() if s.status == "pending"]
        return sorted(pending, key=lambda s: (s.priority.value, -s.confidence))[:limit]

    async def implement_suggestion(self, suggestion_id: UUID, agent_id: str):
        """Mark a suggestion as being implemented."""
        if suggestion_id in self.suggestions:
            self.suggestions[suggestion_id].status = "implementing"
            self.suggestions[suggestion_id].implemented_by = agent_id
```

### Claude Marketplace & Plugins Integration

Integrate with Claude's marketplace for tools and plugins, allowing agents to discover and use new capabilities.

```yaml
# config/marketplace.yaml
marketplace:
  enabled: true
  auto_update: true
  update_check_interval_hours: 24

  # Approved plugin sources
  sources:
    - name: anthropic-official
      url: https://marketplace.anthropic.com/plugins
      trusted: true
    - name: community
      url: https://plugins.ai-infrastructure.dev
      trusted: false
      require_approval: true

  # Installed plugins
  installed:
    - name: web-browser
      version: "1.2.0"
      source: anthropic-official
      enabled: true
      agents: ["research_agent"]

    - name: code-interpreter
      version: "2.1.0"
      source: anthropic-official
      enabled: true
      agents: ["code_agent", "data_agent"]

    - name: file-editor
      version: "1.0.0"
      source: anthropic-official
      enabled: true
      agents: ["*"]

  # Agent-specific marketplace permissions
  agent_permissions:
    supervisor:
      can_install: true
      can_approve: true
      max_plugins: 50

    code_agent:
      can_install: false
      can_request: true
      allowed_categories: ["development", "testing", "documentation"]

    research_agent:
      can_install: false
      can_request: true
      allowed_categories: ["search", "analysis", "summarization"]
```

```python
# packages/core/src/ai_core/marketplace.py
import httpx
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
import yaml

@dataclass
class MarketplacePlugin:
    id: str
    name: str
    version: str
    description: str
    author: str
    source: str
    category: str
    capabilities: list[str]
    requirements: list[str]
    rating: float
    downloads: int
    verified: bool
    compatible_agents: list[str]

class MarketplaceClient:
    """Client for Claude marketplace and plugin management."""

    def __init__(self, config_path: str = "config/marketplace.yaml"):
        with open(config_path) as f:
            self.config = yaml.safe_load(f)["marketplace"]
        self.installed_plugins: dict[str, MarketplacePlugin] = {}

    async def search_plugins(
        self,
        query: str = None,
        category: str = None,
        agent_type: str = None
    ) -> list[MarketplacePlugin]:
        """Search for plugins in the marketplace."""
        plugins = []

        for source in self.config["sources"]:
            if not source.get("trusted") and self.config.get("trusted_only", False):
                continue

            async with httpx.AsyncClient() as client:
                params = {"q": query, "category": category, "agent": agent_type}
                response = await client.get(
                    f"{source['url']}/search",
                    params={k: v for k, v in params.items() if v}
                )
                if response.status_code == 200:
                    for p in response.json().get("plugins", []):
                        plugins.append(MarketplacePlugin(
                            source=source["name"],
                            **p
                        ))

        return plugins

    async def install_plugin(
        self,
        plugin_id: str,
        source: str,
        agents: list[str] = None,
        requester: str = None
    ) -> bool:
        """Install a plugin from the marketplace."""
        # Check permissions
        if requester:
            permissions = self.config["agent_permissions"].get(requester, {})
            if not permissions.get("can_install"):
                if permissions.get("can_request"):
                    await self._request_approval(plugin_id, source, requester)
                    return False
                raise PermissionError(f"Agent {requester} cannot install plugins")

        # Fetch plugin details
        plugin = await self._fetch_plugin(plugin_id, source)

        # Verify compatibility
        if agents:
            for agent in agents:
                if plugin.compatible_agents != ["*"] and agent not in plugin.compatible_agents:
                    raise ValueError(f"Plugin not compatible with {agent}")

        # Download and install
        await self._download_plugin(plugin)
        await self._install_plugin_files(plugin)

        # Register with agents
        self.installed_plugins[plugin.id] = plugin
        await self._register_with_agents(plugin, agents or plugin.compatible_agents)

        return True

    async def update_plugins(self):
        """Check for and apply plugin updates."""
        for plugin_id, plugin in self.installed_plugins.items():
            latest = await self._fetch_plugin(plugin_id, plugin.source)
            if latest.version > plugin.version:
                print(f"Updating {plugin.name} from {plugin.version} to {latest.version}")
                await self.install_plugin(plugin_id, plugin.source)

    async def get_agent_tools(self, agent_type: str) -> list[dict]:
        """Get all tools available to an agent from installed plugins."""
        tools = []
        for plugin in self.installed_plugins.values():
            if "*" in plugin.compatible_agents or agent_type in plugin.compatible_agents:
                tools.extend(await self._load_plugin_tools(plugin))
        return tools

    async def _register_with_agents(self, plugin: MarketplacePlugin, agents: list[str]):
        """Register plugin tools with specified agents."""
        tools = await self._load_plugin_tools(plugin)
        for agent in agents:
            await self.redis.hset(f"agent:{agent}:plugins", plugin.id, {
                "name": plugin.name,
                "version": plugin.version,
                "tools": [t["name"] for t in tools]
            })

class PluginAutoDiscovery:
    """Automatically discover and suggest relevant plugins."""

    def __init__(self, marketplace: MarketplaceClient, redis_client):
        self.marketplace = marketplace
        self.redis = redis_client

    async def analyze_agent_needs(self, agent_id: str) -> list[MarketplacePlugin]:
        """Analyze agent's recent tasks and suggest relevant plugins."""
        # Get recent tasks
        tasks = await self.redis.lrange(f"agent:{agent_id}:tasks:completed", 0, 100)

        # Analyze task patterns
        categories_needed = self._analyze_task_categories(tasks)

        # Search marketplace for relevant plugins
        suggestions = []
        for category in categories_needed:
            plugins = await self.marketplace.search_plugins(category=category)
            suggestions.extend(plugins[:3])

        return suggestions

    async def suggest_on_error(self, agent_id: str, error: dict) -> Optional[MarketplacePlugin]:
        """Suggest a plugin that might help with an error."""
        # Search for plugins that handle this type of error
        plugins = await self.marketplace.search_plugins(
            query=error.get("type", "") + " " + error.get("message", "")[:50]
        )

        if plugins:
            return plugins[0]
        return None
```

### Agent Voting on Priorities

Agents can vote on task priorities and suggest work items, creating a collaborative decision-making process.

```python
# packages/core/src/ai_core/voting.py
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Optional
from uuid import UUID, uuid4
import asyncio

class VoteType(Enum):
    PRIORITY = "priority"           # Vote on task priority
    IMPROVEMENT = "improvement"     # Vote on improvement suggestions
    RESOURCE = "resource"           # Vote on resource allocation
    STRATEGY = "strategy"           # Vote on approach/strategy

@dataclass
class VotingItem:
    id: UUID = field(default_factory=uuid4)
    type: VoteType = VoteType.PRIORITY
    title: str = ""
    description: str = ""
    options: list[str] = field(default_factory=list)
    proposer: str = ""              # Agent that proposed
    created_at: datetime = field(default_factory=datetime.utcnow)
    deadline: Optional[datetime] = None
    votes: dict[str, str] = field(default_factory=dict)  # agent_id -> option
    rationales: dict[str, str] = field(default_factory=dict)  # agent_id -> reasoning
    status: str = "open"            # open, closed, decided
    result: Optional[str] = None

@dataclass
class WorkProposal:
    id: UUID = field(default_factory=uuid4)
    title: str = ""
    description: str = ""
    proposed_by: str = ""
    task_type: str = ""
    estimated_effort: str = ""      # low, medium, high
    priority_votes: dict[str, int] = field(default_factory=dict)  # agent_id -> 1-5
    endorsements: list[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.utcnow)
    status: str = "proposed"        # proposed, approved, rejected, in_progress, completed

class AgentVotingSystem:
    """Democratic voting system for agent collaboration."""

    def __init__(self, redis_client, agents: list[str]):
        self.redis = redis_client
        self.agents = agents
        self.active_votes: dict[UUID, VotingItem] = {}
        self.work_proposals: dict[UUID, WorkProposal] = {}

    async def create_vote(
        self,
        vote_type: VoteType,
        title: str,
        description: str,
        options: list[str],
        proposer: str,
        deadline_hours: int = 24
    ) -> VotingItem:
        """Create a new voting item."""
        vote = VotingItem(
            type=vote_type,
            title=title,
            description=description,
            options=options,
            proposer=proposer,
            deadline=datetime.utcnow() + timedelta(hours=deadline_hours)
        )

        self.active_votes[vote.id] = vote

        # Notify all agents
        await self.redis.publish("voting:new", {
            "id": str(vote.id),
            "type": vote_type.value,
            "title": title,
            "options": options,
            "deadline": vote.deadline.isoformat()
        })

        # Schedule automatic closing
        asyncio.create_task(self._schedule_close(vote))

        return vote

    async def cast_vote(
        self,
        vote_id: UUID,
        agent_id: str,
        choice: str,
        rationale: str = None
    ) -> bool:
        """Cast a vote on an item."""
        if vote_id not in self.active_votes:
            raise ValueError(f"Vote {vote_id} not found")

        vote = self.active_votes[vote_id]

        if vote.status != "open":
            raise ValueError("Voting is closed")

        if choice not in vote.options:
            raise ValueError(f"Invalid choice: {choice}")

        vote.votes[agent_id] = choice
        if rationale:
            vote.rationales[agent_id] = rationale

        # Broadcast vote
        await self.redis.publish("voting:cast", {
            "vote_id": str(vote_id),
            "agent": agent_id,
            "choice": choice
        })

        # Check if all agents have voted
        if len(vote.votes) >= len(self.agents):
            await self._close_vote(vote)

        return True

    async def propose_work(
        self,
        title: str,
        description: str,
        proposed_by: str,
        task_type: str,
        estimated_effort: str
    ) -> WorkProposal:
        """Propose a new work item for the team."""
        proposal = WorkProposal(
            title=title,
            description=description,
            proposed_by=proposed_by,
            task_type=task_type,
            estimated_effort=estimated_effort
        )

        self.work_proposals[proposal.id] = proposal

        # Notify all agents
        await self.redis.publish("proposals:new", {
            "id": str(proposal.id),
            "title": title,
            "proposed_by": proposed_by,
            "task_type": task_type
        })

        return proposal

    async def vote_priority(
        self,
        proposal_id: UUID,
        agent_id: str,
        priority: int  # 1-5, 5 being highest
    ):
        """Vote on a work proposal's priority."""
        if proposal_id not in self.work_proposals:
            raise ValueError(f"Proposal {proposal_id} not found")

        proposal = self.work_proposals[proposal_id]
        proposal.priority_votes[agent_id] = max(1, min(5, priority))

        # Calculate average priority
        avg_priority = sum(proposal.priority_votes.values()) / len(proposal.priority_votes)

        # Auto-approve if high priority consensus
        if len(proposal.priority_votes) >= len(self.agents) * 0.6:
            if avg_priority >= 4.0:
                proposal.status = "approved"
                await self._queue_approved_work(proposal)

    async def endorse_proposal(self, proposal_id: UUID, agent_id: str):
        """Endorse a work proposal."""
        if proposal_id not in self.work_proposals:
            raise ValueError(f"Proposal {proposal_id} not found")

        proposal = self.work_proposals[proposal_id]
        if agent_id not in proposal.endorsements:
            proposal.endorsements.append(agent_id)

        # Auto-approve if majority endorsement
        if len(proposal.endorsements) >= len(self.agents) * 0.5:
            proposal.status = "approved"
            await self._queue_approved_work(proposal)

    async def get_consensus_priorities(self) -> list[WorkProposal]:
        """Get work items sorted by consensus priority."""
        approved = [p for p in self.work_proposals.values() if p.status == "approved"]
        return sorted(
            approved,
            key=lambda p: (
                sum(p.priority_votes.values()) / max(len(p.priority_votes), 1),
                len(p.endorsements)
            ),
            reverse=True
        )

    async def _close_vote(self, vote: VotingItem):
        """Close voting and determine result."""
        vote.status = "closed"

        # Count votes
        vote_counts = {}
        for choice in vote.votes.values():
            vote_counts[choice] = vote_counts.get(choice, 0) + 1

        # Determine winner
        if vote_counts:
            vote.result = max(vote_counts, key=vote_counts.get)

        # Broadcast result
        await self.redis.publish("voting:closed", {
            "vote_id": str(vote.id),
            "result": vote.result,
            "counts": vote_counts,
            "rationales": vote.rationales
        })

    async def _schedule_close(self, vote: VotingItem):
        """Schedule automatic vote closing."""
        if vote.deadline:
            delay = (vote.deadline - datetime.utcnow()).total_seconds()
            if delay > 0:
                await asyncio.sleep(delay)
                if vote.status == "open":
                    await self._close_vote(vote)

    async def _queue_approved_work(self, proposal: WorkProposal):
        """Queue approved work for execution."""
        avg_priority = sum(proposal.priority_votes.values()) / max(len(proposal.priority_votes), 1)

        await self.redis.zadd("tasks:approved", {
            str(proposal.id): avg_priority
        })

        await self.redis.publish("proposals:approved", {
            "id": str(proposal.id),
            "title": proposal.title,
            "priority": avg_priority
        })


# Example: Agent proposing work and voting
async def example_voting_workflow():
    """Example of agents proposing and voting on work."""
    voting = AgentVotingSystem(redis, ["supervisor", "code_agent", "qa_agent"])

    # Code agent proposes a refactoring task
    proposal = await voting.propose_work(
        title="Refactor authentication module",
        description="The auth module has grown complex. Suggest splitting into smaller services.",
        proposed_by="code_agent",
        task_type="refactor",
        estimated_effort="medium"
    )

    # Other agents vote on priority
    await voting.vote_priority(proposal.id, "supervisor", priority=4)
    await voting.vote_priority(proposal.id, "qa_agent", priority=5)  # QA sees security benefit
    await voting.vote_priority(proposal.id, "code_agent", priority=4)

    # QA agent endorses it
    await voting.endorse_proposal(proposal.id, "qa_agent")

    # Supervisor creates a vote on approach
    vote = await voting.create_vote(
        vote_type=VoteType.STRATEGY,
        title="Auth refactoring approach",
        description="How should we approach the auth module refactoring?",
        options=[
            "Incremental refactor with feature flags",
            "Complete rewrite with new design",
            "Extract to microservice"
        ],
        proposer="supervisor",
        deadline_hours=12
    )

    # Agents vote with rationale
    await voting.cast_vote(
        vote.id, "code_agent",
        choice="Incremental refactor with feature flags",
        rationale="Lower risk, can ship incrementally"
    )
    await voting.cast_vote(
        vote.id, "qa_agent",
        choice="Incremental refactor with feature flags",
        rationale="Easier to test in stages"
    )
```

---

## Implementation Phases

### Phase 1: Foundation (Week 1-2)
- [ ] Project setup, Docker Compose (Redis, Qdrant, PostgreSQL)
- [ ] Core packages: config, logging, messaging
- [ ] Memory package with OpenAI embeddings + Qdrant
- [ ] PAI memory structure setup
- [ ] Basic tmux manager

### Phase 2: Agent Framework (Week 3-4)
- [ ] Base agent class with Claude integration
- [ ] Supervisor agent with routing logic
- [ ] First domain agent (code_agent)
- [ ] Inter-agent communication via Redis
- [ ] PAI Algorithm integration

### Phase 3: Multi-Agent System (Week 5-6)
- [ ] Remaining agents (data, infra, research, qa)
- [ ] Agent health monitoring
- [ ] Task orchestration patterns
- [ ] PAI hook system
- [ ] Learning signal capture

### Phase 4: Infrastructure Agent (Week 7)
- [ ] Nginx configuration tools
- [ ] Domain management (add/remove)
- [ ] SSL/Certbot integration
- [ ] Docker management tools
- [ ] SSH access setup

### Phase 5: API & Backend (Week 8-9)
- [ ] FastAPI application setup
- [ ] Authentication (JWT + OAuth)
- [ ] WebSocket real-time chat
- [ ] File upload handling
- [ ] Domain management API

### Phase 6: Web Portal (Week 10-11)
- [ ] Next.js setup with shadcn/ui
- [ ] Authentication pages
- [ ] Chat interface with streaming
- [ ] Agent dashboard
- [ ] Domain management UI

### Phase 7: Voice & Polish (Week 12)
- [ ] OpenAI Whisper integration (STT)
- [ ] OpenAI TTS integration
- [ ] Voice UI components
- [ ] Installer script
- [ ] Documentation

---

## Environment Variables

```bash
# .env.example

# === PAID API SERVICES ===
ANTHROPIC_API_KEY=sk-ant-...           # Claude API
OPENAI_API_KEY=sk-...                   # Embeddings, Whisper, TTS

# === AWS SECRETS MANAGER ===
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_SECRETS_PREFIX=ai-infrastructure/  # Prefix for all secrets

# === CLOUDFLARE (Paid Account) ===
CLOUDFLARE_API_KEY=...                 # Global API Key (Account Settings)
CLOUDFLARE_EMAIL=your@email.com        # Account email
CLOUDFLARE_ACCOUNT_ID=...              # Account ID
CLOUDFLARE_ZONE_IDS=zone1,zone2,...    # Comma-separated Zone IDs for managed domains

# === GITHUB ===
GITHUB_PAT=ghp_...                     # Personal Access Token
GITHUB_OWNER=your-username             # GitHub username or org
GITHUB_REPO=ai-infrastructure-backup   # Backup repository
GITHUB_BRANCH=main                     # Branch for backups

# === FREE INFRASTRUCTURE ===
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=ai_infra
POSTGRES_PASSWORD=<from-aws-secrets>
POSTGRES_DB=ai_infrastructure

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=<from-aws-secrets>

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=<from-aws-secrets>

# === APPLICATION ===
JWT_SECRET=<from-aws-secrets>
JWT_ALGORITHM=HS256
JWT_EXPIRY_HOURS=24

# === DOMAINS ===
PRIMARY_DOMAIN=portal.example.com
API_DOMAIN=api.example.com
WEBROOT_BASE=/var/www

# === SSH ===
SSH_PORT=22
SSH_ALLOWED_USERS=root,admin
```

---

## Quick Start (After Implementation)

```bash
# One-line install
curl -fsSL https://raw.githubusercontent.com/user/AI-Infrastructure/main/install.sh | bash

# Or manual setup
git clone https://github.com/user/AI-Infrastructure.git
cd AI-Infrastructure
cp .env.example .env
# Edit .env with your API keys

# Start infrastructure
docker-compose up -d

# Start agents
./scripts/start-agents.sh

# Access
# Web Portal: https://portal.your-domain.com
# SSH: ssh root@your-server then `tmux attach -t ai-infrastructure`
```

---

## 25. GUI Settings Management

A unified, intuitive settings interface that makes all configuration options easy to understand and control.

### Settings Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SETTINGS MANAGEMENT SYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Settings UI   â”‚    â”‚  Settings API   â”‚    â”‚ Settings Store  â”‚             â”‚
â”‚  â”‚  (Next.js)      â”‚â—„â”€â”€â–ºâ”‚  (FastAPI)      â”‚â—„â”€â”€â–ºâ”‚ (PostgreSQL)    â”‚             â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚             â”‚
â”‚  â”‚ â€¢ Visual forms  â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Persistence   â”‚             â”‚
â”‚  â”‚ â€¢ Real-time     â”‚    â”‚ â€¢ Type checking â”‚    â”‚ â€¢ History       â”‚             â”‚
â”‚  â”‚ â€¢ Search        â”‚    â”‚ â€¢ Webhooks      â”‚    â”‚ â€¢ Rollback      â”‚             â”‚
â”‚  â”‚ â€¢ Categories    â”‚    â”‚ â€¢ Auth          â”‚    â”‚ â€¢ Encryption    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Settings Categories

```python
# src/settings/categories.py

from enum import Enum
from dataclasses import dataclass, field
from typing import Any, Optional, List, Dict, Callable
import re

class SettingType(Enum):
    TEXT = "text"              # Single line text input
    PASSWORD = "password"      # Hidden text (API keys)
    NUMBER = "number"          # Numeric input with +/- controls
    SLIDER = "slider"          # Range slider with min/max
    TOGGLE = "toggle"          # On/off switch
    SELECT = "select"          # Dropdown selection
    MULTI_SELECT = "multi"     # Multiple selection chips
    COLOR = "color"            # Color picker
    TEXTAREA = "textarea"      # Multi-line text
    FILE = "file"              # File upload
    JSON = "json"              # JSON editor
    CRON = "cron"              # Cron expression builder
    KEY_VALUE = "key_value"    # Key-value pair list

class SettingCategory(Enum):
    API_KEYS = "api_keys"
    AGENTS = "agents"
    DATABASE = "database"
    MEMORY = "memory"
    SECURITY = "security"
    NOTIFICATIONS = "notifications"
    APPEARANCE = "appearance"
    PERFORMANCE = "performance"
    BACKUP = "backup"
    DOMAINS = "domains"
    VOICE = "voice"
    PLUGINS = "plugins"

@dataclass
class SettingDefinition:
    """Definition of a single setting with UI metadata."""
    key: str
    label: str
    description: str
    category: SettingCategory
    type: SettingType
    default: Any

    # UI Metadata
    icon: str = ""
    placeholder: str = ""
    help_url: str = ""

    # Validation
    required: bool = False
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    pattern: Optional[str] = None  # Regex for validation
    options: List[Dict[str, str]] = field(default_factory=list)  # For select/multi

    # Display
    display_order: int = 0
    visible: bool = True
    advanced: bool = False  # Hidden in simple mode
    restart_required: bool = False

    # Dependencies
    depends_on: Optional[str] = None  # Show only if another setting is true
    disabled_when: Optional[str] = None  # Disable based on condition

    def validate(self, value: Any) -> tuple[bool, str]:
        """Validate a value against this setting's rules."""
        if self.required and not value:
            return False, f"{self.label} is required"

        if value is None:
            return True, ""

        if self.type == SettingType.NUMBER or self.type == SettingType.SLIDER:
            if self.min_value is not None and value < self.min_value:
                return False, f"{self.label} must be at least {self.min_value}"
            if self.max_value is not None and value > self.max_value:
                return False, f"{self.label} must be at most {self.max_value}"

        if self.pattern and self.type == SettingType.TEXT:
            if not re.match(self.pattern, str(value)):
                return False, f"{self.label} format is invalid"

        return True, ""


# All settings definitions
SETTINGS_REGISTRY: List[SettingDefinition] = [
    # ===== API KEYS =====
    SettingDefinition(
        key="anthropic_api_key",
        label="Claude API Key",
        description="Your Anthropic API key for Claude access",
        category=SettingCategory.API_KEYS,
        type=SettingType.PASSWORD,
        default="",
        icon="ğŸ”‘",
        placeholder="sk-ant-...",
        required=True,
        pattern=r"^sk-ant-.*",
        help_url="https://console.anthropic.com/settings/keys",
        display_order=1
    ),
    SettingDefinition(
        key="openai_api_key",
        label="OpenAI API Key",
        description="For embeddings, Whisper (speech-to-text), and TTS",
        category=SettingCategory.API_KEYS,
        type=SettingType.PASSWORD,
        default="",
        icon="ğŸ”‘",
        placeholder="sk-...",
        required=True,
        pattern=r"^sk-.*",
        help_url="https://platform.openai.com/api-keys",
        display_order=2
    ),
    SettingDefinition(
        key="cloudflare_api_key",
        label="Cloudflare Global API Key",
        description="For DNS, CDN, and security management",
        category=SettingCategory.API_KEYS,
        type=SettingType.PASSWORD,
        default="",
        icon="â˜ï¸",
        placeholder="Your Global API Key",
        help_url="https://dash.cloudflare.com/profile/api-tokens",
        display_order=3
    ),
    SettingDefinition(
        key="github_pat",
        label="GitHub Personal Access Token",
        description="For backups and version control sync",
        category=SettingCategory.API_KEYS,
        type=SettingType.PASSWORD,
        default="",
        icon="ğŸ™",
        placeholder="ghp_...",
        pattern=r"^ghp_.*",
        help_url="https://github.com/settings/tokens",
        display_order=4
    ),

    # ===== AGENTS =====
    SettingDefinition(
        key="supervisor_enabled",
        label="Enable Supervisor Agent",
        description="Main orchestrator that coordinates all other agents",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ‘‘",
        display_order=1
    ),
    SettingDefinition(
        key="code_agent_enabled",
        label="Enable Code Agent",
        description="Handles code generation, review, and refactoring",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ’»",
        display_order=2
    ),
    SettingDefinition(
        key="data_agent_enabled",
        label="Enable Data Agent",
        description="Manages databases, queries, and data transformations",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ“Š",
        display_order=3
    ),
    SettingDefinition(
        key="infra_agent_enabled",
        label="Enable Infrastructure Agent",
        description="Handles deployments, Docker, and system administration",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ—ï¸",
        display_order=4
    ),
    SettingDefinition(
        key="research_agent_enabled",
        label="Enable Research Agent",
        description="Web research, API discovery, and documentation lookup",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ”¬",
        display_order=5
    ),
    SettingDefinition(
        key="qa_agent_enabled",
        label="Enable QA Agent",
        description="Testing, validation, and quality assurance",
        category=SettingCategory.AGENTS,
        type=SettingType.TOGGLE,
        default=True,
        icon="âœ…",
        display_order=6
    ),
    SettingDefinition(
        key="agent_temperature",
        label="Agent Creativity",
        description="Higher values make responses more creative, lower values more focused",
        category=SettingCategory.AGENTS,
        type=SettingType.SLIDER,
        default=0.7,
        icon="ğŸŒ¡ï¸",
        min_value=0.0,
        max_value=1.0,
        display_order=7
    ),
    SettingDefinition(
        key="agent_max_tokens",
        label="Max Response Length",
        description="Maximum tokens per agent response",
        category=SettingCategory.AGENTS,
        type=SettingType.NUMBER,
        default=4096,
        icon="ğŸ“",
        min_value=256,
        max_value=100000,
        display_order=8
    ),
    SettingDefinition(
        key="agent_model",
        label="Claude Model",
        description="Which Claude model to use for agents",
        category=SettingCategory.AGENTS,
        type=SettingType.SELECT,
        default="claude-sonnet-4-20250514",
        icon="ğŸ¤–",
        options=[
            {"value": "claude-sonnet-4-20250514", "label": "Claude Sonnet 4 (Recommended)"},
            {"value": "claude-opus-4-20250514", "label": "Claude Opus 4 (Most capable)"},
            {"value": "claude-3-5-haiku-20241022", "label": "Claude 3.5 Haiku (Fastest)"}
        ],
        display_order=9
    ),

    # ===== MEMORY =====
    SettingDefinition(
        key="memory_hot_ttl_hours",
        label="Hot Memory Duration",
        description="How long to keep frequently accessed memories in fast storage",
        category=SettingCategory.MEMORY,
        type=SettingType.NUMBER,
        default=24,
        icon="ğŸ”¥",
        min_value=1,
        max_value=168,
        display_order=1
    ),
    SettingDefinition(
        key="memory_warm_ttl_days",
        label="Warm Memory Duration",
        description="Days before moving memories to cold storage",
        category=SettingCategory.MEMORY,
        type=SettingType.NUMBER,
        default=7,
        icon="ğŸŒ¡ï¸",
        min_value=1,
        max_value=90,
        display_order=2
    ),
    SettingDefinition(
        key="memory_max_size_gb",
        label="Max Memory Size (GB)",
        description="Maximum size for the vector database",
        category=SettingCategory.MEMORY,
        type=SettingType.SLIDER,
        default=10,
        icon="ğŸ’¾",
        min_value=1,
        max_value=100,
        display_order=3
    ),
    SettingDefinition(
        key="embedding_model",
        label="Embedding Model",
        description="OpenAI model for generating embeddings",
        category=SettingCategory.MEMORY,
        type=SettingType.SELECT,
        default="text-embedding-3-small",
        icon="ğŸ§®",
        options=[
            {"value": "text-embedding-3-small", "label": "Small (Recommended - cost effective)"},
            {"value": "text-embedding-3-large", "label": "Large (Higher quality)"},
            {"value": "text-embedding-ada-002", "label": "Ada 002 (Legacy)"}
        ],
        display_order=4
    ),
    SettingDefinition(
        key="auto_cleanup_enabled",
        label="Auto Cleanup",
        description="Automatically clean up old logs and temporary files",
        category=SettingCategory.MEMORY,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ§¹",
        display_order=5
    ),

    # ===== SECURITY =====
    SettingDefinition(
        key="command_allowlist_enabled",
        label="Enable Command Allowlist",
        description="Only allow pre-approved commands to be executed",
        category=SettingCategory.SECURITY,
        type=SettingType.TOGGLE,
        default=True,
        icon="âœ…",
        display_order=1
    ),
    SettingDefinition(
        key="command_allowlist",
        label="Allowed Commands",
        description="Commands that agents are permitted to execute",
        category=SettingCategory.SECURITY,
        type=SettingType.MULTI_SELECT,
        default=["git", "npm", "pip", "docker", "ls", "cat", "grep"],
        icon="ğŸ“‹",
        options=[
            {"value": "git", "label": "git"},
            {"value": "npm", "label": "npm"},
            {"value": "pip", "label": "pip"},
            {"value": "docker", "label": "docker"},
            {"value": "kubectl", "label": "kubectl"},
            {"value": "ls", "label": "ls"},
            {"value": "cat", "label": "cat"},
            {"value": "grep", "label": "grep"},
            {"value": "curl", "label": "curl"},
            {"value": "wget", "label": "wget"}
        ],
        depends_on="command_allowlist_enabled",
        display_order=2
    ),
    SettingDefinition(
        key="network_egress_filter",
        label="Network Egress Filtering",
        description="Filter outbound network connections",
        category=SettingCategory.SECURITY,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸŒ",
        display_order=3
    ),
    SettingDefinition(
        key="audit_logging_enabled",
        label="Audit Logging",
        description="Log all agent actions for security review",
        category=SettingCategory.SECURITY,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ“",
        display_order=4
    ),
    SettingDefinition(
        key="require_approval_destructive",
        label="Require Approval for Destructive Actions",
        description="Pause for human approval before deleting files, dropping tables, etc.",
        category=SettingCategory.SECURITY,
        type=SettingType.TOGGLE,
        default=True,
        icon="âš ï¸",
        display_order=5
    ),
    SettingDefinition(
        key="session_timeout_minutes",
        label="Session Timeout",
        description="Minutes of inactivity before logging out",
        category=SettingCategory.SECURITY,
        type=SettingType.NUMBER,
        default=60,
        icon="â°",
        min_value=5,
        max_value=480,
        display_order=6
    ),

    # ===== NOTIFICATIONS =====
    SettingDefinition(
        key="notifications_enabled",
        label="Enable Notifications",
        description="Receive notifications for important events",
        category=SettingCategory.NOTIFICATIONS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ””",
        display_order=1
    ),
    SettingDefinition(
        key="notification_channels",
        label="Notification Channels",
        description="Where to send notifications",
        category=SettingCategory.NOTIFICATIONS,
        type=SettingType.MULTI_SELECT,
        default=["browser", "email"],
        icon="ğŸ“¢",
        options=[
            {"value": "browser", "label": "Browser Push"},
            {"value": "email", "label": "Email"},
            {"value": "slack", "label": "Slack"},
            {"value": "discord", "label": "Discord"},
            {"value": "webhook", "label": "Custom Webhook"}
        ],
        depends_on="notifications_enabled",
        display_order=2
    ),
    SettingDefinition(
        key="notify_on_task_complete",
        label="Notify on Task Completion",
        description="Get notified when agents complete tasks",
        category=SettingCategory.NOTIFICATIONS,
        type=SettingType.TOGGLE,
        default=True,
        icon="âœ…",
        depends_on="notifications_enabled",
        display_order=3
    ),
    SettingDefinition(
        key="notify_on_error",
        label="Notify on Errors",
        description="Get notified when agents encounter errors",
        category=SettingCategory.NOTIFICATIONS,
        type=SettingType.TOGGLE,
        default=True,
        icon="âŒ",
        depends_on="notifications_enabled",
        display_order=4
    ),

    # ===== APPEARANCE =====
    SettingDefinition(
        key="theme",
        label="Theme",
        description="Visual theme for the portal",
        category=SettingCategory.APPEARANCE,
        type=SettingType.SELECT,
        default="system",
        icon="ğŸ¨",
        options=[
            {"value": "light", "label": "Light"},
            {"value": "dark", "label": "Dark"},
            {"value": "system", "label": "System (Auto)"}
        ],
        display_order=1
    ),
    SettingDefinition(
        key="accent_color",
        label="Accent Color",
        description="Primary accent color for the UI",
        category=SettingCategory.APPEARANCE,
        type=SettingType.COLOR,
        default="#6366f1",
        icon="ğŸ¨",
        display_order=2
    ),
    SettingDefinition(
        key="compact_mode",
        label="Compact Mode",
        description="Use smaller spacing and fonts",
        category=SettingCategory.APPEARANCE,
        type=SettingType.TOGGLE,
        default=False,
        icon="ğŸ“",
        display_order=3
    ),
    SettingDefinition(
        key="show_agent_avatars",
        label="Show Agent Avatars",
        description="Display avatar icons for each agent",
        category=SettingCategory.APPEARANCE,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ–¼ï¸",
        display_order=4
    ),

    # ===== PERFORMANCE =====
    SettingDefinition(
        key="max_concurrent_tasks",
        label="Max Concurrent Tasks",
        description="Maximum tasks that can run simultaneously across all agents",
        category=SettingCategory.PERFORMANCE,
        type=SettingType.SLIDER,
        default=5,
        icon="âš¡",
        min_value=1,
        max_value=20,
        display_order=1
    ),
    SettingDefinition(
        key="task_timeout_seconds",
        label="Task Timeout",
        description="Maximum seconds a single task can run",
        category=SettingCategory.PERFORMANCE,
        type=SettingType.NUMBER,
        default=300,
        icon="â±ï¸",
        min_value=30,
        max_value=3600,
        display_order=2
    ),
    SettingDefinition(
        key="enable_caching",
        label="Enable Response Caching",
        description="Cache similar queries to reduce API costs",
        category=SettingCategory.PERFORMANCE,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ’¨",
        display_order=3
    ),
    SettingDefinition(
        key="cache_ttl_minutes",
        label="Cache Duration",
        description="Minutes to cache responses",
        category=SettingCategory.PERFORMANCE,
        type=SettingType.NUMBER,
        default=30,
        icon="â°",
        min_value=1,
        max_value=1440,
        depends_on="enable_caching",
        display_order=4
    ),

    # ===== BACKUP =====
    SettingDefinition(
        key="auto_backup_enabled",
        label="Automatic Backups",
        description="Automatically backup configuration and data",
        category=SettingCategory.BACKUP,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ’¾",
        display_order=1
    ),
    SettingDefinition(
        key="backup_schedule",
        label="Backup Schedule",
        description="When to run automatic backups",
        category=SettingCategory.BACKUP,
        type=SettingType.CRON,
        default="0 2 * * *",
        icon="ğŸ“…",
        depends_on="auto_backup_enabled",
        display_order=2
    ),
    SettingDefinition(
        key="backup_retention_days",
        label="Backup Retention",
        description="Days to keep old backups",
        category=SettingCategory.BACKUP,
        type=SettingType.NUMBER,
        default=30,
        icon="ğŸ“¦",
        min_value=1,
        max_value=365,
        depends_on="auto_backup_enabled",
        display_order=3
    ),
    SettingDefinition(
        key="backup_to_github",
        label="Backup to GitHub",
        description="Push backups to GitHub repository",
        category=SettingCategory.BACKUP,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ™",
        depends_on="auto_backup_enabled",
        display_order=4
    ),

    # ===== VOICE =====
    SettingDefinition(
        key="voice_enabled",
        label="Enable Voice",
        description="Enable voice input and output",
        category=SettingCategory.VOICE,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ¤",
        display_order=1
    ),
    SettingDefinition(
        key="voice_model",
        label="TTS Voice",
        description="Voice for text-to-speech output",
        category=SettingCategory.VOICE,
        type=SettingType.SELECT,
        default="nova",
        icon="ğŸ”Š",
        options=[
            {"value": "alloy", "label": "Alloy (Neutral)"},
            {"value": "echo", "label": "Echo (Male)"},
            {"value": "fable", "label": "Fable (Storytelling)"},
            {"value": "onyx", "label": "Onyx (Deep)"},
            {"value": "nova", "label": "Nova (Female)"},
            {"value": "shimmer", "label": "Shimmer (Soft)"}
        ],
        depends_on="voice_enabled",
        display_order=2
    ),
    SettingDefinition(
        key="voice_speed",
        label="Speech Speed",
        description="Speed of text-to-speech output",
        category=SettingCategory.VOICE,
        type=SettingType.SLIDER,
        default=1.0,
        icon="â©",
        min_value=0.5,
        max_value=2.0,
        depends_on="voice_enabled",
        display_order=3
    ),
    SettingDefinition(
        key="auto_listen",
        label="Auto Listen",
        description="Automatically start listening after speaking",
        category=SettingCategory.VOICE,
        type=SettingType.TOGGLE,
        default=False,
        icon="ğŸ‘‚",
        depends_on="voice_enabled",
        display_order=4
    ),

    # ===== PLUGINS =====
    SettingDefinition(
        key="plugins_enabled",
        label="Enable Plugins",
        description="Allow installation of marketplace plugins",
        category=SettingCategory.PLUGINS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ§©",
        display_order=1
    ),
    SettingDefinition(
        key="auto_update_plugins",
        label="Auto-Update Plugins",
        description="Automatically update plugins when new versions are available",
        category=SettingCategory.PLUGINS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ”„",
        depends_on="plugins_enabled",
        display_order=2
    ),
    SettingDefinition(
        key="plugin_sandbox",
        label="Plugin Sandbox",
        description="Run plugins in isolated environment for security",
        category=SettingCategory.PLUGINS,
        type=SettingType.TOGGLE,
        default=True,
        icon="ğŸ”’",
        depends_on="plugins_enabled",
        display_order=3
    ),
]
```

### Settings Service

```python
# src/settings/service.py

from typing import Any, Dict, List, Optional
from datetime import datetime
import json
import asyncpg
from .categories import SETTINGS_REGISTRY, SettingDefinition, SettingCategory

class SettingsService:
    """Centralized settings management with persistence and history."""

    def __init__(self, db_pool: asyncpg.Pool):
        self.db = db_pool
        self._cache: Dict[str, Any] = {}
        self._registry = {s.key: s for s in SETTINGS_REGISTRY}

    async def initialize(self):
        """Initialize settings table and load defaults."""
        await self.db.execute('''
            CREATE TABLE IF NOT EXISTS settings (
                key VARCHAR(255) PRIMARY KEY,
                value JSONB NOT NULL,
                updated_at TIMESTAMP DEFAULT NOW(),
                updated_by VARCHAR(255)
            );

            CREATE TABLE IF NOT EXISTS settings_history (
                id SERIAL PRIMARY KEY,
                key VARCHAR(255) NOT NULL,
                old_value JSONB,
                new_value JSONB,
                changed_at TIMESTAMP DEFAULT NOW(),
                changed_by VARCHAR(255),
                reason TEXT
            );
        ''')

        # Load existing settings into cache
        rows = await self.db.fetch("SELECT key, value FROM settings")
        for row in rows:
            self._cache[row['key']] = json.loads(row['value'])

        # Apply defaults for missing settings
        for setting in SETTINGS_REGISTRY:
            if setting.key not in self._cache:
                self._cache[setting.key] = setting.default

    async def get(self, key: str) -> Any:
        """Get a setting value."""
        if key in self._cache:
            return self._cache[key]

        if key in self._registry:
            return self._registry[key].default

        return None

    async def get_all(self) -> Dict[str, Any]:
        """Get all settings."""
        result = {}
        for setting in SETTINGS_REGISTRY:
            result[setting.key] = self._cache.get(setting.key, setting.default)
        return result

    async def get_by_category(self, category: SettingCategory) -> Dict[str, Any]:
        """Get settings for a specific category."""
        result = {}
        for setting in SETTINGS_REGISTRY:
            if setting.category == category:
                result[setting.key] = self._cache.get(setting.key, setting.default)
        return result

    async def set(
        self,
        key: str,
        value: Any,
        user: str = "system",
        reason: str = ""
    ) -> tuple[bool, str]:
        """Set a setting value with validation."""
        if key not in self._registry:
            return False, f"Unknown setting: {key}"

        setting = self._registry[key]

        # Validate
        is_valid, error = setting.validate(value)
        if not is_valid:
            return False, error

        old_value = self._cache.get(key)

        # Persist
        await self.db.execute('''
            INSERT INTO settings (key, value, updated_at, updated_by)
            VALUES ($1, $2, NOW(), $3)
            ON CONFLICT (key) DO UPDATE SET
                value = $2,
                updated_at = NOW(),
                updated_by = $3
        ''', key, json.dumps(value), user)

        # Record history
        await self.db.execute('''
            INSERT INTO settings_history (key, old_value, new_value, changed_by, reason)
            VALUES ($1, $2, $3, $4, $5)
        ''', key, json.dumps(old_value), json.dumps(value), user, reason)

        # Update cache
        self._cache[key] = value

        return True, ""

    async def set_bulk(
        self,
        settings: Dict[str, Any],
        user: str = "system",
        reason: str = ""
    ) -> Dict[str, tuple[bool, str]]:
        """Set multiple settings at once."""
        results = {}
        for key, value in settings.items():
            results[key] = await self.set(key, value, user, reason)
        return results

    async def reset_to_default(self, key: str, user: str = "system") -> bool:
        """Reset a setting to its default value."""
        if key not in self._registry:
            return False

        default = self._registry[key].default
        await self.set(key, default, user, "Reset to default")
        return True

    async def reset_all(self, user: str = "system") -> None:
        """Reset all settings to defaults."""
        for setting in SETTINGS_REGISTRY:
            await self.reset_to_default(setting.key, user)

    async def get_history(
        self,
        key: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict]:
        """Get settings change history."""
        if key:
            rows = await self.db.fetch('''
                SELECT * FROM settings_history
                WHERE key = $1
                ORDER BY changed_at DESC
                LIMIT $2
            ''', key, limit)
        else:
            rows = await self.db.fetch('''
                SELECT * FROM settings_history
                ORDER BY changed_at DESC
                LIMIT $1
            ''', limit)

        return [dict(row) for row in rows]

    async def export_settings(self) -> str:
        """Export all settings as JSON."""
        settings = await self.get_all()
        return json.dumps(settings, indent=2)

    async def import_settings(
        self,
        json_data: str,
        user: str = "system"
    ) -> Dict[str, tuple[bool, str]]:
        """Import settings from JSON."""
        try:
            settings = json.loads(json_data)
            return await self.set_bulk(settings, user, "Imported from JSON")
        except json.JSONDecodeError as e:
            return {"_error": (False, f"Invalid JSON: {e}")}

    def get_schema(self) -> List[Dict]:
        """Get the settings schema for UI generation."""
        schema = []
        for setting in sorted(SETTINGS_REGISTRY, key=lambda s: (s.category.value, s.display_order)):
            schema.append({
                "key": setting.key,
                "label": setting.label,
                "description": setting.description,
                "category": setting.category.value,
                "type": setting.type.value,
                "default": setting.default,
                "icon": setting.icon,
                "placeholder": setting.placeholder,
                "help_url": setting.help_url,
                "required": setting.required,
                "min_value": setting.min_value,
                "max_value": setting.max_value,
                "options": setting.options,
                "advanced": setting.advanced,
                "restart_required": setting.restart_required,
                "depends_on": setting.depends_on,
                "disabled_when": setting.disabled_when
            })
        return schema
```

### Settings API Endpoints

```python
# src/api/routes/settings.py

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import Any, Dict, Optional, List
from ...settings.service import SettingsService
from ...settings.categories import SettingCategory
from ..auth import get_current_user

router = APIRouter(prefix="/api/settings", tags=["settings"])

class SettingUpdate(BaseModel):
    value: Any
    reason: Optional[str] = ""

class BulkSettingUpdate(BaseModel):
    settings: Dict[str, Any]
    reason: Optional[str] = ""

@router.get("/schema")
async def get_settings_schema(
    settings_service: SettingsService = Depends()
):
    """Get the complete settings schema for UI generation."""
    return {
        "schema": settings_service.get_schema(),
        "categories": [c.value for c in SettingCategory]
    }

@router.get("/")
async def get_all_settings(
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Get all current settings values."""
    return await settings_service.get_all()

@router.get("/category/{category}")
async def get_category_settings(
    category: str,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Get settings for a specific category."""
    try:
        cat = SettingCategory(category)
        return await settings_service.get_by_category(cat)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"Invalid category: {category}")

@router.get("/{key}")
async def get_setting(
    key: str,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Get a single setting value."""
    value = await settings_service.get(key)
    if value is None:
        raise HTTPException(status_code=404, detail=f"Setting not found: {key}")
    return {"key": key, "value": value}

@router.put("/{key}")
async def update_setting(
    key: str,
    update: SettingUpdate,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Update a single setting."""
    success, error = await settings_service.set(
        key,
        update.value,
        user.username,
        update.reason
    )
    if not success:
        raise HTTPException(status_code=400, detail=error)
    return {"key": key, "value": update.value, "updated": True}

@router.put("/")
async def update_bulk_settings(
    update: BulkSettingUpdate,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Update multiple settings at once."""
    results = await settings_service.set_bulk(
        update.settings,
        user.username,
        update.reason
    )
    errors = {k: v[1] for k, v in results.items() if not v[0]}
    if errors:
        raise HTTPException(status_code=400, detail={"errors": errors})
    return {"updated": True, "count": len(update.settings)}

@router.post("/{key}/reset")
async def reset_setting(
    key: str,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Reset a setting to its default value."""
    success = await settings_service.reset_to_default(key, user.username)
    if not success:
        raise HTTPException(status_code=404, detail=f"Setting not found: {key}")
    return {"key": key, "reset": True}

@router.post("/reset-all")
async def reset_all_settings(
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Reset all settings to defaults. Requires admin."""
    if not user.is_admin:
        raise HTTPException(status_code=403, detail="Admin required")
    await settings_service.reset_all(user.username)
    return {"reset": True}

@router.get("/history/")
async def get_settings_history(
    key: Optional[str] = None,
    limit: int = 100,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Get settings change history."""
    return await settings_service.get_history(key, limit)

@router.get("/export")
async def export_settings(
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Export all settings as JSON."""
    return {"json": await settings_service.export_settings()}

@router.post("/import")
async def import_settings(
    json_data: str,
    settings_service: SettingsService = Depends(),
    user = Depends(get_current_user)
):
    """Import settings from JSON. Requires admin."""
    if not user.is_admin:
        raise HTTPException(status_code=403, detail="Admin required")
    results = await settings_service.import_settings(json_data, user.username)
    errors = {k: v[1] for k, v in results.items() if not v[0]}
    if errors:
        raise HTTPException(status_code=400, detail={"errors": errors})
    return {"imported": True}
```

### Settings UI Components (React/Next.js)

```typescript
// src/portal/components/settings/SettingsPage.tsx

'use client';

import { useState, useEffect } from 'react';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Input } from '@/components/ui/input';
import { Button } from '@/components/ui/button';
import { Switch } from '@/components/ui/switch';
import { Slider } from '@/components/ui/slider';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Badge } from '@/components/ui/badge';
import { toast } from 'sonner';
import { Search, Save, RotateCcw, Download, Upload, History, HelpCircle } from 'lucide-react';

interface SettingSchema {
  key: string;
  label: string;
  description: string;
  category: string;
  type: string;
  default: any;
  icon: string;
  placeholder?: string;
  help_url?: string;
  required?: boolean;
  min_value?: number;
  max_value?: number;
  options?: Array<{ value: string; label: string }>;
  advanced?: boolean;
  restart_required?: boolean;
  depends_on?: string;
}

const CATEGORY_INFO: Record<string, { icon: string; label: string; description: string }> = {
  api_keys: { icon: 'ğŸ”‘', label: 'API Keys', description: 'Configure API credentials for external services' },
  agents: { icon: 'ğŸ¤–', label: 'Agents', description: 'Configure AI agent behavior and capabilities' },
  database: { icon: 'ğŸ’¾', label: 'Database', description: 'Database connection and storage settings' },
  memory: { icon: 'ğŸ§ ', label: 'Memory', description: 'Vector database and memory management' },
  security: { icon: 'ğŸ”’', label: 'Security', description: 'Security policies and access controls' },
  notifications: { icon: 'ğŸ””', label: 'Notifications', description: 'Alert and notification preferences' },
  appearance: { icon: 'ğŸ¨', label: 'Appearance', description: 'Visual theme and UI customization' },
  performance: { icon: 'âš¡', label: 'Performance', description: 'Performance tuning and optimization' },
  backup: { icon: 'ğŸ’¾', label: 'Backup', description: 'Backup and recovery settings' },
  domains: { icon: 'ğŸŒ', label: 'Domains', description: 'Domain and hosting configuration' },
  voice: { icon: 'ğŸ¤', label: 'Voice', description: 'Voice input and output settings' },
  plugins: { icon: 'ğŸ§©', label: 'Plugins', description: 'Plugin and marketplace settings' },
};

export default function SettingsPage() {
  const [schema, setSchema] = useState<SettingSchema[]>([]);
  const [values, setValues] = useState<Record<string, any>>({});
  const [originalValues, setOriginalValues] = useState<Record<string, any>>({});
  const [categories, setCategories] = useState<string[]>([]);
  const [activeCategory, setActiveCategory] = useState<string>('');
  const [searchQuery, setSearchQuery] = useState('');
  const [showAdvanced, setShowAdvanced] = useState(false);
  const [hasChanges, setHasChanges] = useState(false);
  const [saving, setSaving] = useState(false);

  useEffect(() => {
    loadSettings();
  }, []);

  useEffect(() => {
    // Check for unsaved changes
    const changed = Object.keys(values).some(
      key => JSON.stringify(values[key]) !== JSON.stringify(originalValues[key])
    );
    setHasChanges(changed);
  }, [values, originalValues]);

  const loadSettings = async () => {
    const [schemaRes, valuesRes] = await Promise.all([
      fetch('/api/settings/schema'),
      fetch('/api/settings/')
    ]);

    const schemaData = await schemaRes.json();
    const valuesData = await valuesRes.json();

    setSchema(schemaData.schema);
    setCategories(schemaData.categories);
    setActiveCategory(schemaData.categories[0]);
    setValues(valuesData);
    setOriginalValues(valuesData);
  };

  const handleValueChange = (key: string, value: any) => {
    setValues(prev => ({ ...prev, [key]: value }));
  };

  const saveSettings = async () => {
    setSaving(true);
    try {
      const changedSettings: Record<string, any> = {};
      Object.keys(values).forEach(key => {
        if (JSON.stringify(values[key]) !== JSON.stringify(originalValues[key])) {
          changedSettings[key] = values[key];
        }
      });

      const res = await fetch('/api/settings/', {
        method: 'PUT',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ settings: changedSettings, reason: 'Updated via UI' })
      });

      if (res.ok) {
        setOriginalValues({ ...values });
        toast.success('Settings saved successfully');
      } else {
        const error = await res.json();
        toast.error(`Failed to save: ${JSON.stringify(error.detail)}`);
      }
    } finally {
      setSaving(false);
    }
  };

  const resetCategory = async (category: string) => {
    const categorySettings = schema.filter(s => s.category === category);
    const resetValues: Record<string, any> = {};
    categorySettings.forEach(s => {
      resetValues[s.key] = s.default;
    });
    setValues(prev => ({ ...prev, ...resetValues }));
  };

  const exportSettings = async () => {
    const res = await fetch('/api/settings/export');
    const data = await res.json();
    const blob = new Blob([data.json], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'settings.json';
    a.click();
  };

  const filteredSchema = schema.filter(setting => {
    // Category filter
    if (setting.category !== activeCategory) return false;

    // Advanced filter
    if (setting.advanced && !showAdvanced) return false;

    // Search filter
    if (searchQuery) {
      const query = searchQuery.toLowerCase();
      return (
        setting.label.toLowerCase().includes(query) ||
        setting.description.toLowerCase().includes(query) ||
        setting.key.toLowerCase().includes(query)
      );
    }

    // Dependency filter
    if (setting.depends_on && !values[setting.depends_on]) return false;

    return true;
  });

  const renderSettingInput = (setting: SettingSchema) => {
    const value = values[setting.key] ?? setting.default;

    switch (setting.type) {
      case 'toggle':
        return (
          <Switch
            checked={value}
            onCheckedChange={(checked) => handleValueChange(setting.key, checked)}
          />
        );

      case 'text':
      case 'password':
        return (
          <Input
            type={setting.type}
            value={value}
            onChange={(e) => handleValueChange(setting.key, e.target.value)}
            placeholder={setting.placeholder}
            className="max-w-md"
          />
        );

      case 'number':
        return (
          <Input
            type="number"
            value={value}
            onChange={(e) => handleValueChange(setting.key, Number(e.target.value))}
            min={setting.min_value}
            max={setting.max_value}
            className="max-w-32"
          />
        );

      case 'slider':
        return (
          <div className="flex items-center gap-4 max-w-md">
            <Slider
              value={[value]}
              onValueChange={([v]) => handleValueChange(setting.key, v)}
              min={setting.min_value}
              max={setting.max_value}
              step={setting.max_value && setting.max_value <= 2 ? 0.1 : 1}
              className="flex-1"
            />
            <span className="text-sm font-mono w-12 text-right">{value}</span>
          </div>
        );

      case 'select':
        return (
          <Select value={value} onValueChange={(v) => handleValueChange(setting.key, v)}>
            <SelectTrigger className="max-w-md">
              <SelectValue />
            </SelectTrigger>
            <SelectContent>
              {setting.options?.map(opt => (
                <SelectItem key={opt.value} value={opt.value}>
                  {opt.label}
                </SelectItem>
              ))}
            </SelectContent>
          </Select>
        );

      case 'multi':
        return (
          <div className="flex flex-wrap gap-2">
            {setting.options?.map(opt => (
              <Badge
                key={opt.value}
                variant={value?.includes(opt.value) ? 'default' : 'outline'}
                className="cursor-pointer"
                onClick={() => {
                  const current = value || [];
                  const newValue = current.includes(opt.value)
                    ? current.filter((v: string) => v !== opt.value)
                    : [...current, opt.value];
                  handleValueChange(setting.key, newValue);
                }}
              >
                {opt.label}
              </Badge>
            ))}
          </div>
        );

      case 'color':
        return (
          <div className="flex items-center gap-2">
            <input
              type="color"
              value={value}
              onChange={(e) => handleValueChange(setting.key, e.target.value)}
              className="w-10 h-10 rounded cursor-pointer"
            />
            <Input
              value={value}
              onChange={(e) => handleValueChange(setting.key, e.target.value)}
              className="max-w-32 font-mono"
            />
          </div>
        );

      default:
        return (
          <Input
            value={value}
            onChange={(e) => handleValueChange(setting.key, e.target.value)}
            placeholder={setting.placeholder}
            className="max-w-md"
          />
        );
    }
  };

  return (
    <div className="container mx-auto py-6 max-w-6xl">
      <div className="flex items-center justify-between mb-6">
        <div>
          <h1 className="text-3xl font-bold">Settings</h1>
          <p className="text-muted-foreground">
            Configure your AI infrastructure
          </p>
        </div>

        <div className="flex items-center gap-2">
          <Button variant="outline" onClick={exportSettings}>
            <Download className="w-4 h-4 mr-2" />
            Export
          </Button>
          <Button variant="outline">
            <Upload className="w-4 h-4 mr-2" />
            Import
          </Button>
          <Button variant="outline">
            <History className="w-4 h-4 mr-2" />
            History
          </Button>
          <Button
            onClick={saveSettings}
            disabled={!hasChanges || saving}
          >
            <Save className="w-4 h-4 mr-2" />
            {saving ? 'Saving...' : 'Save Changes'}
          </Button>
        </div>
      </div>

      {/* Search and filters */}
      <div className="flex items-center gap-4 mb-6">
        <div className="relative flex-1 max-w-md">
          <Search className="absolute left-3 top-1/2 -translate-y-1/2 w-4 h-4 text-muted-foreground" />
          <Input
            placeholder="Search settings..."
            value={searchQuery}
            onChange={(e) => setSearchQuery(e.target.value)}
            className="pl-10"
          />
        </div>
        <div className="flex items-center gap-2">
          <Switch
            id="advanced"
            checked={showAdvanced}
            onCheckedChange={setShowAdvanced}
          />
          <label htmlFor="advanced" className="text-sm">
            Show advanced settings
          </label>
        </div>
      </div>

      {/* Category tabs */}
      <Tabs value={activeCategory} onValueChange={setActiveCategory}>
        <TabsList className="flex flex-wrap h-auto gap-1 mb-6">
          {categories.map(cat => (
            <TabsTrigger key={cat} value={cat} className="flex items-center gap-1">
              <span>{CATEGORY_INFO[cat]?.icon}</span>
              <span>{CATEGORY_INFO[cat]?.label || cat}</span>
            </TabsTrigger>
          ))}
        </TabsList>

        {categories.map(cat => (
          <TabsContent key={cat} value={cat}>
            <Card>
              <CardHeader>
                <div className="flex items-center justify-between">
                  <div>
                    <CardTitle className="flex items-center gap-2">
                      <span className="text-2xl">{CATEGORY_INFO[cat]?.icon}</span>
                      {CATEGORY_INFO[cat]?.label || cat}
                    </CardTitle>
                    <CardDescription>
                      {CATEGORY_INFO[cat]?.description}
                    </CardDescription>
                  </div>
                  <Button
                    variant="ghost"
                    size="sm"
                    onClick={() => resetCategory(cat)}
                  >
                    <RotateCcw className="w-4 h-4 mr-2" />
                    Reset to defaults
                  </Button>
                </div>
              </CardHeader>
              <CardContent>
                <div className="space-y-6">
                  {filteredSchema.map(setting => (
                    <div
                      key={setting.key}
                      className="flex items-start justify-between py-4 border-b last:border-0"
                    >
                      <div className="flex-1 pr-8">
                        <div className="flex items-center gap-2">
                          <span className="text-lg">{setting.icon}</span>
                          <label className="font-medium">
                            {setting.label}
                          </label>
                          {setting.required && (
                            <Badge variant="destructive" className="text-xs">
                              Required
                            </Badge>
                          )}
                          {setting.restart_required && (
                            <Badge variant="secondary" className="text-xs">
                              Restart required
                            </Badge>
                          )}
                          {setting.help_url && (
                            <a
                              href={setting.help_url}
                              target="_blank"
                              rel="noopener noreferrer"
                              className="text-muted-foreground hover:text-foreground"
                            >
                              <HelpCircle className="w-4 h-4" />
                            </a>
                          )}
                        </div>
                        <p className="text-sm text-muted-foreground mt-1">
                          {setting.description}
                        </p>
                      </div>
                      <div className="flex-shrink-0">
                        {renderSettingInput(setting)}
                      </div>
                    </div>
                  ))}

                  {filteredSchema.length === 0 && (
                    <div className="text-center py-8 text-muted-foreground">
                      No settings found
                    </div>
                  )}
                </div>
              </CardContent>
            </Card>
          </TabsContent>
        ))}
      </Tabs>

      {/* Unsaved changes indicator */}
      {hasChanges && (
        <div className="fixed bottom-4 right-4 bg-primary text-primary-foreground px-4 py-2 rounded-lg shadow-lg flex items-center gap-2">
          <span>You have unsaved changes</span>
          <Button size="sm" variant="secondary" onClick={saveSettings}>
            Save now
          </Button>
        </div>
      )}
    </div>
  );
}
```

### Settings Features Summary

| Feature | Description |
|---------|-------------|
| **Categorized Settings** | 12 logical categories with icons and descriptions |
| **Visual Controls** | Toggles, sliders, dropdowns, color pickers, multi-select |
| **Search** | Real-time search across all settings |
| **Validation** | Client and server-side validation with helpful errors |
| **Dependencies** | Settings can show/hide based on other settings |
| **History** | Full change history with rollback capability |
| **Import/Export** | Backup and restore settings as JSON |
| **Defaults** | Reset individual settings or entire categories |
| **Advanced Mode** | Hide complex settings from basic users |
| **Help Links** | Direct links to documentation for each setting |
| **Unsaved Indicator** | Visual reminder of pending changes |
| **Real-time Preview** | Changes reflect immediately in UI |

---

## Next Steps

1. **Review this plan** - Does this architecture meet your needs?
2. **Clarify requirements** - Any specific features to add/remove?
3. **Begin implementation** - Start with Phase 1 foundation

Ready to proceed when you approve this plan.
