# BELIEFS.md - BlackBook Reviews (Dev)

## PROJECT PURPOSE
BlackBook Reviews is a verified-identity review platform for professional companionship — where both providers and clients prove who they are, reviews come from confirmed connections, and privacy is protected by architecture, not policy.

**Core Mission**: To build the trust infrastructure that lets professional companionship operate with verification, safety, and dignity — proving these aren't trade-offs.

## CORE VALUES (Non-Negotiable)

### 1. Privacy by Architecture
Not privacy by policy. Not privacy by promise. Privacy because the system cannot violate it.
- E2E encryption means BlackBook can't read messages even if compelled
- Verification documents deleted after badges issued
- Data minimization as default, not afterthought
- **Test**: "If we were subpoenaed tomorrow, what could we hand over?" Answer: "Almost nothing."

### 2. Verification Without Surveillance
Prove who someone is without knowing who they are. The badge persists; the data doesn't.
- Verified pseudonyms, not exposed identities
- Cryptographic proof, not stored documents
- Trust through architecture, not through collecting leverage
- **Test**: "Does this feature require us to know more about users than necessary?"

### 3. Provider Dignity
Providers are professionals building businesses, not inventory to be monetized. The platform serves them; they don't serve the platform.
- Providers own their profiles and reputations
- Providers rate clients (mutual accountability)
- Providers control visibility, contact, availability
- **Test**: "Does this decision empower providers or extract from them?"

### 4. Transparent Accountability
Every decision explainable. Every action reversible. No black boxes.
- AI decisions logged with confidence scores
- Human review on significant actions
- Clear appeals process with real consideration
- **Test**: "Can we explain to a user exactly why this happened to their account?"

### 5. Safety as Foundation
Not safety vs. privacy. Not safety vs. usability. Safety through good architecture.
- Verification distinguishes consent from exploitation
- NCMEC integration for mandatory reporting
- Tools for providers to screen, block, report
- **Test**: "Does this make both providers and clients genuinely safer?"

## VALUE HIERARCHY (When Values Conflict)
1. **Safety** — Preventing real harm trumps everything
2. **Privacy** — Protecting users from exposure
3. **Provider Dignity** — Empowering, not exploiting
4. **Transparency** — Explainable decisions
5. **Verification** — Trust through proof

*Note: The architecture should make these conflicts rare. That's the point.*

## RED LINES (Never Cross)

### Data Practices
- Never sell, share, or monetize user data
- Never retain data beyond operational necessity
- Never build backdoors or break our own encryption

### Business Models
- Never charge providers to remove negative reviews
- Never take percentage cuts from transactions
- Never implement pay-to-play verification or trust scores
- Never build features that expose provider real identity to clients

### Partnerships
- Never partner with entities that profit from exploitation
- Never accept investment with strings that compromise values
- Never partner with law enforcement for surveillance

### Features
- Never build tracking or location surveillance
- Never build social pressure mechanics
- Never build features that expose user patterns
- Never build automated bans without human review

## GUIDING PRINCIPLES (Daily Decisions)

### 1. "When in Doubt, Delete It"
Every piece of data is a liability. Default answer to "should we store this?" is no.
- **Test**: "Would we regret having this if it leaked?"

### 2. "Make the Safe Choice the Easy Choice"
Safety shouldn't require effort. The path of least resistance should be the path of most protection.
- **Test**: "What happens if they click through without reading?"

### 3. "Explain It Like They'll Screenshot It"
Every message should be clear enough to survive being shared publicly.
- **Test**: "Would we be proud if this ended up on Twitter?"

### 4. "Build for the Person With the Most to Lose"
Optimize for the user whose safety, privacy, or livelihood is most at risk.
- **Test**: "How does this affect someone in danger?"

## REJECTION STATEMENT
BlackBook rejects the premise that verification, safety, and privacy are trade-offs. We build systems that can't betray users, not systems that promise not to.

**We are not neutral. We are on the side of the people using this platform — especially the ones with the most at risk.**

---
*Last updated: 2026-01-27 05:47:06 UTC*
